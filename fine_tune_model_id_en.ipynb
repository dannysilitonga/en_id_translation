{"cells":[{"cell_type":"markdown","metadata":{"id":"2NHZ3XxoDfHL"},"source":["# Machine Translation from Indonesian to English"]},{"cell_type":"markdown","metadata":{"id":"4YB4T5CBD2kJ"},"source":["## Preliminary Import Statements"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27681,"status":"ok","timestamp":1653284989391,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"jTyISPAf9G05","outputId":"f917715a-bd42-45b1-8f1a-0db8f0e2f737"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7837,"status":"ok","timestamp":1653285000969,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"9dK8e-qfD1ig","outputId":"78cfc444-09ab-4601-cbf4-6ad26efcdeb0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 15.0 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n","\u001b[K     |████████████████████████████████| 84 kB 3.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 50.4 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 71.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3088,"status":"ok","timestamp":1653285023719,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"jQ7YBJ8eHfSR","outputId":"dfc78568-d697-4d79-8ea1-ef1e0e9fd6bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.19.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.64.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.12.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.21.6)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.7.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (21.3)\n","Collecting sentencepiece!=0.1.92,>=0.1.91\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 14.0 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[sentencepiece]) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers[sentencepiece]) (3.8.0)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers[sentencepiece]) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (3.0.4)\n","Installing collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"]}],"source":["!pip install transformers[sentencepiece]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2862,"status":"ok","timestamp":1653285029667,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"TssYM3_mIZV7","outputId":"648936ce-298a-463a-ccc2-ee52ec73d571"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]}],"source":["!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7254,"status":"ok","timestamp":1653285038861,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"b9Ja-x8xap39","outputId":"27425d08-9e65-4434-8fa5-8cd37ffaeef9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting datasets\n","  Downloading datasets-2.2.2-py3-none-any.whl (346 kB)\n","\u001b[K     |████████████████████████████████| 346 kB 14.2 MB/s \n","\u001b[?25hCollecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 82.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 83.2 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 56.6 MB/s \n","\u001b[?25hRequirement already satisfied: dill<0.3.5 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.6.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 84.6 MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 76.3 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.3 MB/s \n","\u001b[?25hCollecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 83.0 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.2.2 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3333,"status":"ok","timestamp":1653285070600,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"a5uccjzd30wB","outputId":"7be87478-03ae-4845-fafd-e56dff1e0d21"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting sacrebleu==1.5.0\n","  Downloading sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n","\u001b[?25l\r\u001b[K     |█████                           | 10 kB 32.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20 kB 37.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 30 kB 27.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 40 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 51 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 61 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 65 kB 4.1 MB/s \n","\u001b[?25hCollecting portalocker\n","  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n","Installing collected packages: portalocker, sacrebleu\n","Successfully installed portalocker-2.4.0 sacrebleu-1.5.0\n"]}],"source":["!pip install sacrebleu==1.5.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6272,"status":"ok","timestamp":1653285080037,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"AtHVnotW4BEC","outputId":"afa5ded9-411e-4843-c2f5-03a382e5ea74"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n","Collecting nltk\n","  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n","\u001b[?25l\r\u001b[K     |▏                               | 10 kB 39.6 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 41.1 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |▉                               | 40 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 92 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 133 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 143 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 153 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 163 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 174 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 184 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 194 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 204 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 215 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 225 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 235 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 245 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 256 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 266 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 276 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 286 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 296 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 307 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 317 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 327 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 337 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 348 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 358 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 368 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 378 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 389 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 399 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 409 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 419 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 430 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 440 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 450 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 460 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 471 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 481 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 491 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 501 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 512 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 522 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 532 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 542 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 552 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 563 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 573 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 583 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 593 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 604 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 614 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 624 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 634 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 645 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 655 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 665 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 675 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 686 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 696 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 706 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 716 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 727 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 737 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 747 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 757 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 768 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 778 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 788 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 798 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 808 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 819 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 829 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 839 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 849 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 860 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 870 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 880 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 890 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 901 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 911 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 921 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 931 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 942 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 952 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 962 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 972 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 983 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 993 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.0 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.0 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.0 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.0 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.3 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.3 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.3 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.3 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.3 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.3 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.3 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.5 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.5 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5 MB 14.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n","Collecting regex>=2021.8.3\n","  Downloading regex-2022.4.24-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n","\u001b[K     |████████████████████████████████| 749 kB 84.7 MB/s \n","\u001b[?25hInstalling collected packages: regex, nltk\n","  Attempting uninstall: regex\n","    Found existing installation: regex 2019.12.20\n","    Uninstalling regex-2019.12.20:\n","      Successfully uninstalled regex-2019.12.20\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","Successfully installed nltk-3.7 regex-2022.4.24\n"]}],"source":["!pip install -U nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1506,"status":"ok","timestamp":1652804931006,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"GwTMYZ3C2Zny","outputId":"7c216767-579d-4207-c94e-ce075abe1382"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting htop\n","  Downloading htop-1.0.tar.gz (3.4 kB)\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/2a/8d/4c95b827d75574cea634211eabd5fac26dc144fc7ae060cf4ee4b067eec6/htop-1.0.tar.gz#sha256=c705d29fea31a2a0a08cfb4b6def27b75961b1c3dce9f68436885d4206c83af2 (from https://pypi.org/simple/htop/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","\u001b[31mERROR: Could not find a version that satisfies the requirement htop (from versions: 1.0)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for htop\u001b[0m\n"]}],"source":["!pip install htop"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1035,"status":"ok","timestamp":1653078040584,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"eMgleNKp3TCf","outputId":"4f33fdd8-1584-4dc8-bbf4-7529bf2605a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement sacremose (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for sacremose\u001b[0m\n"]}],"source":["!pip install -U sacremose"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14685,"status":"ok","timestamp":1651347803930,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"8J5W9fP5_3-5","outputId":"3740037a-10ec-4901-9c87-c6b6827d0267"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting neptune-client\n","  Downloading neptune-client-0.16.1.tar.gz (316 kB)\n","\u001b[K     |████████████████████████████████| 316 kB 31.4 MB/s \n","\u001b[?25hCollecting bravado\n","  Downloading bravado-11.0.3-py2.py3-none-any.whl (38 kB)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n","Collecting future>=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 69.2 MB/s \n","\u001b[?25hRequirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (3.2.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.3.5)\n","Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n","Collecting PyJWT\n","  Downloading PyJWT-2.3.0-py3-none-any.whl (16 kB)\n","Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (2.23.0)\n","Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.3.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.15.0)\n","Collecting websocket-client!=1.0.0,>=0.35.0\n","  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 2.5 MB/s \n","\u001b[?25hCollecting GitPython>=2.0.8\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 68.9 MB/s \n","\u001b[?25hCollecting boto3>=1.16.0\n","  Downloading boto3-1.22.4-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 62.5 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from neptune-client) (21.3)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.25.11)\n","Collecting swagger-spec-validator>=2.7.4\n","  Downloading swagger_spec_validator-2.7.4-py2.py3-none-any.whl (27 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from neptune-client) (5.4.8)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 8.7 MB/s \n","\u001b[?25hCollecting botocore<1.26.0,>=1.25.4\n","  Downloading botocore-1.25.4-py3-none-any.whl (8.7 MB)\n","\u001b[K     |████████████████████████████████| 8.7 MB 65.1 MB/s \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.26.0,>=1.25.4->boto3>=1.16.0->neptune-client) (2.8.2)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=2.0.8->neptune-client) (4.2.0)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2.10)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from swagger-spec-validator>=2.7.4->neptune-client) (6.0)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from swagger-spec-validator>=2.7.4->neptune-client) (4.3.3)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (1.0.3)\n","Collecting monotonic\n","  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Collecting simplejson\n","  Downloading simplejson-3.17.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (130 kB)\n","\u001b[K     |████████████████████████████████| 130 kB 62.0 MB/s \n","\u001b[?25hCollecting bravado-core>=5.16.1\n","  Downloading bravado_core-5.17.0-py2.py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client) (2022.1)\n","Collecting jsonref\n","  Downloading jsonref-0.2-py3-none-any.whl (9.3 kB)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (5.7.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (4.11.3)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (21.4.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.18.1)\n","Collecting uri-template\n","  Downloading uri_template-1.2.0-py3-none-any.whl (10 kB)\n","Collecting rfc3987\n","  Downloading rfc3987-1.3.8-py2.py3-none-any.whl (13 kB)\n","Collecting webcolors>=1.11\n","  Downloading webcolors-1.11.1-py3-none-any.whl (9.9 kB)\n","Collecting isoduration\n","  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n","Collecting jsonpointer>1.13\n","  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n","Collecting fqdn\n","  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n","Collecting rfc3339-validator\n","  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (3.8.0)\n","Requirement already satisfied: cached-property>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from fqdn->jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.5.2)\n","Collecting arrow>=0.15.0\n","  Downloading arrow-1.2.2-py3-none-any.whl (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 2.6 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->neptune-client) (3.0.8)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->neptune-client) (1.21.6)\n","Building wheels for collected packages: neptune-client, future\n","  Building wheel for neptune-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for neptune-client: filename=neptune_client-0.16.1-py2.py3-none-any.whl size=565960 sha256=e0f15254ccc822b5c1d4ad1d81fd9bd6d35045dc80144b07c37fa939c9f4e92d\n","  Stored in directory: /root/.cache/pip/wheels/8b/1a/02/10440cbdf7d5e3a3a13aab8ed77dfb54504c89b5d22a09bb51\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=1198ff198d873a86988f020c608cefe3c1fe9b7db137ee5e2b0b4cefae051452\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","Successfully built neptune-client future\n","Installing collected packages: arrow, webcolors, uri-template, rfc3987, rfc3339-validator, jsonpointer, jmespath, isoduration, fqdn, swagger-spec-validator, smmap, simplejson, jsonref, botocore, s3transfer, monotonic, gitdb, bravado-core, websocket-client, PyJWT, GitPython, future, bravado, boto3, neptune-client\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","Successfully installed GitPython-3.1.27 PyJWT-2.3.0 arrow-1.2.2 boto3-1.22.4 botocore-1.25.4 bravado-11.0.3 bravado-core-5.17.0 fqdn-1.5.1 future-0.18.2 gitdb-4.0.9 isoduration-20.11.0 jmespath-1.0.0 jsonpointer-2.3 jsonref-0.2 monotonic-1.6 neptune-client-0.16.1 rfc3339-validator-0.1.4 rfc3987-1.3.8 s3transfer-0.5.2 simplejson-3.17.6 smmap-5.0.0 swagger-spec-validator-2.7.4 uri-template-1.2.0 webcolors-1.11.1 websocket-client-1.3.2\n"]}],"source":["!pip install neptune-client\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":782},"executionInfo":{"elapsed":10912,"status":"ok","timestamp":1651348000356,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"PZSn_F4lAo2e","outputId":"4954f90c-89e2-4d52-fba3-719147198aa5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting awscli\n","  Downloading awscli-1.23.4-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 28.3 MB/s \n","\u001b[?25hCollecting six\n","  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting rsa<4.8,>=3.1.2\n","  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n","Collecting botocore==1.25.4\n","  Using cached botocore-1.25.4-py3-none-any.whl (8.7 MB)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Using cached s3transfer-0.5.2-py3-none-any.whl (79 kB)\n","Collecting docutils<0.16,>=0.10\n","  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n","\u001b[K     |████████████████████████████████| 547 kB 61.4 MB/s \n","\u001b[?25hCollecting PyYAML<5.5,>=3.10\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 60.1 MB/s \n","\u001b[?25hCollecting colorama<0.4.5,>=0.2.5\n","  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Collecting python-dateutil<3.0.0,>=2.1\n","  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n","\u001b[K     |████████████████████████████████| 247 kB 81.0 MB/s \n","\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 78.5 MB/s \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Using cached jmespath-1.0.0-py3-none-any.whl (23 kB)\n","Collecting pyasn1>=0.1.3\n","  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 6.0 MB/s \n","\u001b[?25hInstalling collected packages: six, urllib3, python-dateutil, jmespath, pyasn1, botocore, s3transfer, rsa, PyYAML, docutils, colorama, awscli\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n","google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed PyYAML-6.0 awscli-1.23.4 botocore-1.25.4 colorama-0.4.4 docutils-0.17.1 jmespath-1.0.0 pyasn1-0.4.8 python-dateutil-2.8.2 rsa-4.8 s3transfer-0.5.2 six-1.16.0 urllib3-1.26.9\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["botocore","colorama","dateutil","jmespath","pyasn1","six","urllib3","yaml"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install awscli --ignore-installed six"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BWmCnAtu9Vta"},"outputs":[],"source":["import torch\n","import sentencepiece\n","from transformers import pipeline\n","from pprint import pprint"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264,"referenced_widgets":["fc5988eb139d49d59937db95e4238dd7","10badb8dba90407ebdab80d231fa2b95","5320ffb8ced5426c9762345e7171f07a","179c77df68ca45f393bd0c02d791ca86","8b21ebbfda3f465d936e66cbfed82564","83446a27061f4b788e2516d1a1f8c6e3","566758f2ab1f4423965e0dfec6241006","87ecfeece49749ddac1d33319e0bc9ca","525c58a2e1e843718b278a2a6f19aa44","0a3b684d47344ba0b51c7730d8942861","a9091529567a4549b6a4ed0a787b7491","6031bedbcb86448eb48899825e60f1f5","073f687aaec14c048de95a35d4c16299","fdcc1e5745c94b31892b382192a3921b","a7a49c0d0b9148928cb8031f4fdd824b","5487176a237646799fee62f029d1914b","aab036bb3ef2401a89aadfc7f48ab9fa","fcee4a5e6f4a4bdfab3344600c40ebcf","7f33e04d51c4448d9197a5169c9bdf46","27e2ef51344a4557908d34409cc38371","f9051819d73f438ca32917292f5327aa","30b29f05deee41e287a7b711fc689711","f4b6d1c7f9b34d1f93ba7619202dc987","e6843ff996724b85b3a2e8b6ac027490","7bab4c19693c4711bdc1dfdc6c251a8d","d45597bfaa5d46cf8e5d5829242c41b7","09f5ebbe208146048a4874a4364afd84","e11a904b9cc24543beb6830f2dc25d86","d3428049976e435e87f5ada9dbe902fc","ef67951e580141a1a2f3e472cc025a42","ff7d05452a3d4f3f966ac113e7f516f2","15e1f85697fc45c18f5b63e60365e87f","04cf6c8ba1804120ac3e65d94c37355d","15ff2195a9fe4a429546894578b219a6","4058f40961db4b61958215fff9393d64","225cc2fe6b2045309a035668bac02955","16bf3e1c42f34c6c8e9d8f6201603777","c557fa2721394465941ac49a88013956","f20d5ad892cb4474aa42992feb9e07ad","7902cf984322470c967107857a93d42a","07975831e30249c183ea04b2e48c039c","7417377e241648d9848cc5552ab758cd","3d51f361c27c443aa9a3a0dff9305b02","73908abb07f54b00bdc865cb5991991f","a45658cd1aa6436a83801a762247dcd8","98c0eab6a5704263bb11f6d6160b7e06","979b5d121bfd40b8a5a88cd82045d6db","b8b0c36cb6b24cde84453dd3acf1b53c","7b551e4c30cc4c59926197b85291e98e","028c5e2ebc9e464fadbc7285a4e035e0","e8449742b21e4684bf5d811f12b7e2e3","683163103ffd40958b90872620e54caa","a86f5925ca3d4aacb3a51388068e46d2","1ebf4b30011448ba82a5fad89bd68dc4","d73a63dd5a41422ba22d14b9d1411081","41c54e6991d9497598df1aa728930051","8a58c8804ebc43b09398108ece0765cc","5b2765959fdf42ecbf7ae14d3683c903","45a6a0a9cad848cd904617fde51c3e5e","b3ff0bd5955b41b8b1389e3eafea7742","8df51dca54d94ffcbe2249fdebdc4931","5ff57338b1c949689156dc5c894eb008","2dc9e7ff0a5346959a050d40643d59af","b01c25a465ab48688683946ed375a331","fd3ec62eb0fa44368df188aa16ae4870","71b02b116c5a4d4b9627a816fa2448ac"]},"executionInfo":{"elapsed":29964,"status":"ok","timestamp":1653285124540,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"mRkXWKL4Efa1","outputId":"8670a637-f8e7-4ae8-c30e-3e3328140c48"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc5988eb139d49d59937db95e4238dd7","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6031bedbcb86448eb48899825e60f1f5","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/278M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4b6d1c7f9b34d1f93ba7619202dc987","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15ff2195a9fe4a429546894578b219a6","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/782k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a45658cd1aa6436a83801a762247dcd8","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/777k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41c54e6991d9497598df1aa728930051","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.20M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/models/marian/tokenization_marian.py:196: UserWarning: Recommended: pip install sacremoses.\n","  warnings.warn(\"Recommended: pip install sacremoses.\")\n"]}],"source":["translator_id = pipeline(\"translation_id_to_en\", model=\"Helsinki-NLP/opus-mt-id-en\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":793,"status":"ok","timestamp":1653285125293,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"fpfLQLlbGJOo","outputId":"3d00895e-632c-41ae-8a23-b667b1d82a22"},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'translation_text': 'USA Today is a daily middle - market newspaper published by ship owner Gannett, founded by Al Neuharth on September 15, 1982'}]\n"]}],"source":["text ='USA Today adalah koran pasar menengah Amerika sehari-hari yang diterbitkan oleh pemilik kapal, Gannett, didirikan oleh Al Neuharth pada 15 September 1982'\n","translation = translator_id(text)\n","print(translation)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4023,"status":"ok","timestamp":1653285129312,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"qchzYHbFI19T","outputId":"a8ef7e6f-241e-40b0-ea08-f5351e2e553c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/models/marian/tokenization_marian.py:196: UserWarning: Recommended: pip install sacremoses.\n","  warnings.warn(\"Recommended: pip install sacremoses.\")\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-id-en\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yu4WY_gcXHpG"},"outputs":[],"source":["model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-id-en\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1653285132069,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"7rzql5LEXaiZ","outputId":"0acc2605-8a82-4929-8f2e-d9541798ceeb"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': tensor([[ 8992,  4950,  1898, 16985,   127,   536, 12957,  1475,   322,  3673,\n","          3776,   118, 21887,    82,  2090,   625,   773,     2,  2672, 16985,\n","           127,  1475,   322,    26, 11168,    19,   810, 20858,     2,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1]])}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:3538: FutureWarning: \n","`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n","`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n","your targets.\n","\n","Here is a short example:\n","\n","model_inputs = tokenizer(src_texts, ...)\n","with tokenizer.as_target_tokenizer():\n","    labels = tokenizer(tgt_texts, ...)\n","model_inputs[\"labels\"] = labels[\"input_ids\"]\n","\n","See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n","For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n","\n","  warnings.warn(formatted_warning, FutureWarning)\n"]}],"source":["text = \"Pemerintah melaporkan penambahan 247 kasus baru Covid-19 dalam 24 jam terakhir. Penambahan kasus baru itu tersebar di 20 provinsi.\"\n","tokenized_text = tokenizer.prepare_seq2seq_batch([text], return_tensors='pt')\n","print(tokenized_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":560,"status":"ok","timestamp":1653285132609,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"h3lHV0RJXvAe","outputId":"ec0d77da-05c7-4aef-9f85-f3e2dc01f1c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["The government reported an addition of 247 new cases of Covid-19 in the last 24 hours.\n"]}],"source":["translation = model.generate(**tokenized_text)\n","translated_text = tokenizer.batch_decode(translation, skip_special_tokens=True)[0]\n","print(translated_text)"]},{"cell_type":"markdown","metadata":{"id":"ZNWdZjo_aYF5"},"source":["### Import OpenSubtitle Dataset Using Hugging Face"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bVMrEdjVYJdW"},"outputs":[],"source":["from datasets import load_dataset, load_metric"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217,"referenced_widgets":["889dfd625ca442d6a56d40c6ba938a06","ec6f03b1efc14d42813648727da5568a","340066a5fbfa42d0bba9789f125c839a","710da2f7aecd4291994dbd6570f11332","39c31457f69f4161a6eba9bda741d332","f24c7aa7633447ac8e8ec2e9e11b8186","614def8989694fcca71ae35dc7697415","790a499797f14544839b19e94fb09d3b","e8cc05fb9c1a47459b9fe787ce06f317","44fab7ef183c4dd4b85badbfc1d9bc16","711eb042d04349fc93b32fc36f02cdcd","f9f14d98398b4d8ea6338467ee140f63","58f1bab7be894f7c827542b0bf9b2406","abefca5253e941c69c214e040db6c2e0","0426e23aaee24584a6c951d775705a68","90dcc31e72d648bbbeae751b4e25e822","8772cc0bf30546a19f13c3bbea28983c","d619c94a8bcc407aa5fa1335cb7ee844","6f223a1f1e9f4327bb94f2a928855e64","1e389bce39b04129be27e5389f875d9c","0afdd008cf5e40c0af788063e124931c","4a148438382547f8a449b12c8b8bbe2a","d4bb429fd2d049aeafc5b169016a8526","85807622faf34f8c9189dc04ff70bba1","5fe003a4b127450b93be7688286e2757","1fa81d6b52424c59856c43714fc9026a","535b957b74c041b38ebd7c923720c827","3d505402d3474d7e84aaa1bcc7b045c3","233317d26f784026b77df7ccb5836837","d4ae5e20841e46c79e5d226d5c50c6df","a27283c1ce084e8f85a9b3ba5843f0fa","4afde4be70a84f2ba36380d9970c774a","d3922a70290e432098a88c63251ad032","13cbcdeeeb40466495ed48a5c2bc6b70","60bed3deb77e46c3a9f77eb16e9e6e5b","30080f9cfcf546acaf31a258637e3287","3f8e7eb733084c6fb5826aa5c7b0a3f5","e6c67e7ac95c4a6b9ec9a17a2c531ce0","32e78dd6e2fb4f4cba6a755c9a9af601","c337e58e26164402ae8ee6b3f22fc8a1","836597a980a645e682ed7f1caf6eff72","bb4d4b5bb286491193d9d9c5edc8cbdc","8e5dde095f494205b5b1e47dabbe5118","523bb89292a04e9388b567d64d4d9a2c","57e19b3c06e44b119cc3074a815d3d10","6e95651636c6476280e6b5803a4a2bd0","ba9be01c0cab4993829ddc6b60a51602","b36b66b32ae34406b1a8c67fed182045","4f8176d235ca4f508b49a4f78e108f03","c9ffed1821ed4213affbfb473ce0bc33","2d27691eec8448df9dac8a91d6f04997","f724d66f96494647b347efd8d9d793e5","da3f69c007f044d5a5542ef5099e5146","f5a169d447ff49df9590aaa1559205b4","8b3cf22fc7d6416ba8da746235b931de"]},"executionInfo":{"elapsed":1276462,"status":"ok","timestamp":1653286409432,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"-Kv6X0AlahLq","outputId":"a533b002-43d7-4078-8f6e-a9b17377187e"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"889dfd625ca442d6a56d40c6ba938a06","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.27k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f9f14d98398b4d8ea6338467ee140f63","version_major":2,"version_minor":0},"text/plain":["Downloading metadata:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Using custom data configuration en-id-lang1=en,lang2=id\n"]},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset open_subtitles/en-id to /root/.cache/huggingface/datasets/open_subtitles/en-id-lang1=en,lang2=id/0.0.0/c1ec973ca4b6e588740d8f167cc0e24ea3f626e70bc7ffe467e944730500e198...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d4bb429fd2d049aeafc5b169016a8526","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/261M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13cbcdeeeb40466495ed48a5c2bc6b70","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset open_subtitles downloaded and prepared to /root/.cache/huggingface/datasets/open_subtitles/en-id-lang1=en,lang2=id/0.0.0/c1ec973ca4b6e588740d8f167cc0e24ea3f626e70bc7ffe467e944730500e198. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57e19b3c06e44b119cc3074a815d3d10","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["raw_datasets = load_dataset(\"open_subtitles\", lang1=\"en\", lang2=\"id\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1653286409433,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"QT7jJOoej34_","outputId":"d2fbc888-03d4-4576-a24c-74753d4c6233"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'id': ['10', '11'],\n"," 'meta': [{'imdbId': 3244200,\n","           'sentenceIds': {'en': [11], 'id': [12]},\n","           'subtitleId': {'en': 5338913, 'id': 5137634},\n","           'year': 0},\n","          {'imdbId': 3244200,\n","           'sentenceIds': {'en': [12], 'id': [13]},\n","           'subtitleId': {'en': 5338913, 'id': 5137634},\n","           'year': 0}],\n"," 'translation': [{'en': '=Turn this off right now.=',\n","                  'id': '=Matikan ini sekarang juga.='},\n","                 {'en': \"=If you don't turn this off by the time I count to \"\n","                        '10,=',\n","                  'id': '=Kalau kau belum mematikannya saat aku sudah '\n","                        'menghitung sampai 10,='}]}\n"]}],"source":["pprint(raw_datasets['train'][10:12])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1653286409433,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"7kWJMwi3kLGV","outputId":"4e21eb33-d148-4c51-f80e-6db7d0083722"},"outputs":[{"name":"stdout","output_type":"stream","text":["👉 Dataset len(dataset): 1\n","\n","👉 First item 'raw_datasets[0]':\n","{'id': '0',\n"," 'meta': {'imdbId': 3244200,\n","          'sentenceIds': {'en': [1], 'id': [1]},\n","          'subtitleId': {'en': 5338913, 'id': 5137634},\n","          'year': 0},\n"," 'translation': {'en': '-=Episode 13=-', 'id': '-=Episode 13=-'}}\n"]}],"source":["print(f\"👉 Dataset len(dataset): {len(raw_datasets)}\")\n","print(\"\\n👉 First item 'raw_datasets[0]':\")\n","pprint(raw_datasets['train'][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1653286409433,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"CsIci_-rkWbP","outputId":"b9231fe2-037a-429d-f94c-806a4cb514b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'id': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n"," 'meta': [{'imdbId': 3244200,\n","           'sentenceIds': {'en': [1], 'id': [1]},\n","           'subtitleId': {'en': 5338913, 'id': 5137634},\n","           'year': 0},\n","          {'imdbId': 3244200,\n","           'sentenceIds': {'en': [2], 'id': [2]},\n","           'subtitleId': {'en': 5338913, 'id': 5137634},\n","           'year': 0},\n","          {'imdbId': 3244200,\n","           'sentenceIds': {'en': [3], 'id': [3]},\n","           'subtitleId': {'en': 5338913, 'id': 5137634},\n","           'year': 0},\n","          {'imdbId': 3244200,\n","           'sentenceIds': {'en': [4], 'id': [4]},\n","           'subtitleId': {'en': 5338913, 'id': 5137634},\n","           'year': 0},\n","          {'imdbId': 3244200,\n","           'sentenceIds': {'en': [5], 'id': [5]},\n","           'subtitleId': {'en': 5338913, 'id': 5137634},\n","           'year': 0},\n","          {'imdbId': 3244200,\n","           'sentenceIds': {'en': [6], 'id': [6]},\n","           'subtitleId': {'en': 5338913, 'id': 5137634},\n","           'year': 0},\n","          {'imdbId': 3244200,\n","           'sentenceIds': {'en': [7], 'id': [7, 8]},\n","           'subtitleId': {'en': 5338913, 'id': 5137634},\n","           'year': 0},\n","          {'imdbId': 3244200,\n","           'sentenceIds': {'en': [8], 'id': [9]},\n","           'subtitleId': {'en': 5338913, 'id': 5137634},\n","           'year': 0},\n","          {'imdbId': 3244200,\n","           'sentenceIds': {'en': [9], 'id': [10]},\n","           'subtitleId': {'en': 5338913, 'id': 5137634},\n","           'year': 0},\n","          {'imdbId': 3244200,\n","           'sentenceIds': {'en': [10], 'id': [11]},\n","           'subtitleId': {'en': 5338913, 'id': 5137634},\n","           'year': 0}],\n"," 'translation': [{'en': '-=Episode 13=-', 'id': '-=Episode 13=-'},\n","                 {'en': 'People.', 'id': 'Rakyat?'},\n","                 {'en': 'That brat.', 'id': 'Bocah itu.'},\n","                 {'en': 'Is this a tooth for a tooth?',\n","                  'id': 'Apa dia mau balas dendam dengan cara yang sama?'},\n","                 {'en': 'A video message as well?', 'id': 'Dengan video juga?'},\n","                 {'en': 'He just has this capability.',\n","                  'id': 'Hanya ini kemampuannya.'},\n","                 {'en': '=You opened it.=', 'id': '=Kau membukanya? ='},\n","                 {'en': \"=You didn't listen to my advice.=\",\n","                  'id': '=Rupanya kau tidak mendengarkan nasihatku.='},\n","                 {'en': '=Fine.=', 'id': '=Baiklah.='},\n","                 {'en': \"=With an open mind, I'll give you the last chance.=\",\n","                  'id': '=Dengan pikiran terbuka, aku akan memberikanmu '\n","                        'kesempatan terakhir.='}]}\n"]}],"source":["pprint(raw_datasets['train'][:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1653286409433,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"dji44KwmqVVY","outputId":"6697706b-c120-4cc0-fc36-24eff70b5701"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'meta', 'translation'],\n","        num_rows: 9268181\n","    })\n","})"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["raw_datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4dYUDctSp04o"},"outputs":[],"source":["from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2881,"status":"ok","timestamp":1653286412311,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"mrsaQ9N9krAA","outputId":"cd507a23-630e-4a45-be36-0089573c6936"},"outputs":[{"name":"stderr","output_type":"stream","text":["Using custom data configuration en-id-lang1=en,lang2=id\n","Reusing dataset open_subtitles (/root/.cache/huggingface/datasets/open_subtitles/en-id-lang1=en,lang2=id/0.0.0/c1ec973ca4b6e588740d8f167cc0e24ea3f626e70bc7ffe467e944730500e198)\n"]},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'meta', 'translation'],\n","        num_rows: 7414545\n","    })\n","    test: Dataset({\n","        features: ['id', 'meta', 'translation'],\n","        num_rows: 1853636\n","    })\n","})"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["train_test = (load_dataset(\"open_subtitles\", lang1=\"en\", lang2=\"id\", split='train')\n","            .train_test_split(train_size=7414545, test_size=1853636))\n","train_test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3650,"status":"ok","timestamp":1653286415959,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"e8DJgW5-nFMH","outputId":"7b326664-bf90-4497-a72d-d0af636a5fce"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/models/marian/tokenization_marian.py:196: UserWarning: Recommended: pip install sacremoses.\n","  warnings.warn(\"Recommended: pip install sacremoses.\")\n"]}],"source":["model_marianMT = \"Helsinki-NLP/opus-mt-id-en\"\n","tokenizer = AutoTokenizer.from_pretrained(model_marianMT)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0e115c2051564282b3a55315e9cfe9e2","5adcbf032a49476daf4466b21399e89d","08cabece265b47e483c86ede41ef09e2","93305e5242dd42afa8e4ac8babb770fb","66e1513114c3434f96ee79b85148f016","a7892b12329a4e469c70681715dfffad","2266d28e8d0f48cb9c698f922043fa91","979ffe4a2b9f4a5d8d4e89cd398d2bd8","985cc881f04c4a45b7891f36ffe7f8f3","f6517d2802994e12b6b60ff129a2bc44","5da84f48509a4fa78ce566aa096a5765","fa1ea1137abd40d0a298a6e3e3357c1e","84f75fe1ad1c4607930789ae9cb37e75","bec144cd6b174bcb847484997e27f65d","7c0de156195d4c739adb8c7b36f9bb46","d097a6b5fa684abcab4903cd693f430b","abec2930db8d40e69574b8979a440c5d","4e2e456f5d354bc9a262b0d835f9a32d","85d8f484366045fb8d4226255b40da33","75837616283d4696b09aff0907faba44","9a844b23d46d4816a1aaba6473579c7d","3ac86cf829774ac8bb5a4281b0bb3c1e","ef7754f068644d209ed36c38bd7a9f6a","54dd01563bfc4aafa2ae90c9a2841fda","df38dde199364792a9cfbeb77293f32c","7466ecb70e234922b1388bdda7015568","76f380a251cb4775b9419e027ad8280e","4b73e951939d4605ae5374c83f9c42eb","321b9a8602aa4db99048836d074e843c","33a757b8e48541a3a7295f8e15893874","e018b7306dbb451aa3af333be8196904","62e1012e6be648728257418b08fa0d35","059ecc4fbc6940f281596f9581739cd6","741ca23e67fa47d6aea5d477625b6c0c","3a22b300e9064c558436ba043b459b39","93f47689f17144058e40d473c2ce8ac6","fd0724ca2d6947e5bedbd0e4e6b25bf6","c3d1534a71e445dbb91d67fa90822c7a","6571071bbd414b91917788f6f8e83b94","0a52b5832c394b3e974ffbd5f4424397","f3a339662abc451ea3ba6a7f0824d65b","6ef5268580fd4e39b37d369fa396386c","2f3f2477248f41c9b6aa868ca8c558fe","a07c4dd66760488ca08ba9e8ea445d62"]},"executionInfo":{"elapsed":2669,"status":"ok","timestamp":1651351923101,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"zZvMbwcRO9lA","outputId":"a73dc258-613d-41e0-f7a9-b1045adcbe89"},"outputs":[{"name":"stderr","output_type":"stream","text":["https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpf7gl84k4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e115c2051564282b3a55315e9cfe9e2","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/528 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/6e443a2ed9a4346cca5f4fb9986a60fea956b0f74694596632e5d37302cd2d51.6e9c56f90d0ccc4bb88c2360463bcbd3a5d5688b9ba81e6bcea7316ac803e5ca\n","creating metadata file for /root/.cache/huggingface/transformers/6e443a2ed9a4346cca5f4fb9986a60fea956b0f74694596632e5d37302cd2d51.6e9c56f90d0ccc4bb88c2360463bcbd3a5d5688b9ba81e6bcea7316ac803e5ca\n","https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt/resolve/main/sentencepiece.bpe.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmps20v77x_\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa1ea1137abd40d0a298a6e3e3357c1e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt/resolve/main/sentencepiece.bpe.model in cache at /root/.cache/huggingface/transformers/715836a337ea91c1df044351c6041fcac9e268c8836a08c3aae639e8b38b4760.71e50b08dbe7e5375398e165096cacc3d2086119d6a449364490da6908de655e\n","creating metadata file for /root/.cache/huggingface/transformers/715836a337ea91c1df044351c6041fcac9e268c8836a08c3aae639e8b38b4760.71e50b08dbe7e5375398e165096cacc3d2086119d6a449364490da6908de655e\n","https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp6v4m_yro\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef7754f068644d209ed36c38bd7a9f6a","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/717 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/e584858c24b9c062296d83fd0d04e8037a58ca86863388b251e20d15b57d3652.4048b5693f516fd4b429d384e716f4bb0d4831de2b6c9ea2c42a86765c5ee4a1\n","creating metadata file for /root/.cache/huggingface/transformers/e584858c24b9c062296d83fd0d04e8037a58ca86863388b251e20d15b57d3652.4048b5693f516fd4b429d384e716f4bb0d4831de2b6c9ea2c42a86765c5ee4a1\n","loading file https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt/resolve/main/sentencepiece.bpe.model from cache at /root/.cache/huggingface/transformers/715836a337ea91c1df044351c6041fcac9e268c8836a08c3aae639e8b38b4760.71e50b08dbe7e5375398e165096cacc3d2086119d6a449364490da6908de655e\n","loading file https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/e584858c24b9c062296d83fd0d04e8037a58ca86863388b251e20d15b57d3652.4048b5693f516fd4b429d384e716f4bb0d4831de2b6c9ea2c42a86765c5ee4a1\n","loading file https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/6e443a2ed9a4346cca5f4fb9986a60fea956b0f74694596632e5d37302cd2d51.6e9c56f90d0ccc4bb88c2360463bcbd3a5d5688b9ba81e6bcea7316ac803e5ca\n","https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpfmxb7t8y\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"741ca23e67fa47d6aea5d477625b6c0c","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/1ad22be12336f9eec2b9fa372045631e8ffe9e2ca771f6802f88b5b15651f859.c46a0ea4d8cfc938ed324724108be3e06c2fb377cfdbd57ac70f5f589bb03a44\n","creating metadata file for /root/.cache/huggingface/transformers/1ad22be12336f9eec2b9fa372045631e8ffe9e2ca771f6802f88b5b15651f859.c46a0ea4d8cfc938ed324724108be3e06c2fb377cfdbd57ac70f5f589bb03a44\n","loading configuration file https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1ad22be12336f9eec2b9fa372045631e8ffe9e2ca771f6802f88b5b15651f859.c46a0ea4d8cfc938ed324724108be3e06c2fb377cfdbd57ac70f5f589bb03a44\n","Model config MBartConfig {\n","  \"_name_or_path\": \"facebook/mbart-large-50-one-to-many-mmt\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": true,\n","  \"architectures\": [\n","    \"MBartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"mbart\",\n","  \"normalize_before\": true,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"static_position_embeddings\": false,\n","  \"tokenizer_class\": \"MBart50Tokenizer\",\n","  \"transformers_version\": \"4.18.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 250054\n","}\n","\n","loading configuration file https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1ad22be12336f9eec2b9fa372045631e8ffe9e2ca771f6802f88b5b15651f859.c46a0ea4d8cfc938ed324724108be3e06c2fb377cfdbd57ac70f5f589bb03a44\n","Model config MBartConfig {\n","  \"_name_or_path\": \"facebook/mbart-large-50-one-to-many-mmt\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": true,\n","  \"architectures\": [\n","    \"MBartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"mbart\",\n","  \"normalize_before\": true,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"static_position_embeddings\": false,\n","  \"tokenizer_class\": \"MBart50Tokenizer\",\n","  \"transformers_version\": \"4.18.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 250054\n","}\n","\n"]}],"source":["# model_mbart = 'facebook/mbart-large-50-one-to-many-mmt'\n","# from transformers import MBart50TokenizerFast\n","\n","# tokenizer = MBart50TokenizerFast.from_pretrained(model_mbart,src_lang=\"en_XX\",tgt_lang = \"id_ID\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":650,"status":"ok","timestamp":1651351936317,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"LWCRJ6S9PPMa","outputId":"c8a3eb2b-fb90-480d-9488-81a18df808cd"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-en-id/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/4d62c643c511f7fd504d5b8b9fe3e6ffb52b5b4cb4873de79090b34bdca69b37.78724ce53ce73bdd9784bb662a52f86d95686bc90e3b663d223271a92e76786f\n","Model config MarianConfig {\n","  \"_name_or_path\": \"Helsinki-NLP/opus-mt-en-id\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"swish\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"MarianMTModel\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bad_words_ids\": [\n","    [\n","      54795\n","    ]\n","  ],\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 512,\n","  \"decoder_attention_heads\": 8,\n","  \"decoder_ffn_dim\": 2048,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 54795,\n","  \"decoder_vocab_size\": 54796,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 8,\n","  \"encoder_ffn_dim\": 2048,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 0,\n","  \"forced_eos_token_id\": 0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_length\": 512,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"marian\",\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": false,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 54795,\n","  \"scale_embedding\": true,\n","  \"share_encoder_decoder_embeddings\": true,\n","  \"static_position_embeddings\": true,\n","  \"transformers_version\": \"4.18.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 54796\n","}\n","\n","loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-id/resolve/main/source.spm from cache at /root/.cache/huggingface/transformers/7a4dc5f7b845bea742ceb48892830e1d5fe4b0548a229672ec35baaa35c95739.5dd7e33aa4871685cded13a5c668236232baa1b5433a359abb2348f5508e9f26\n","loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-id/resolve/main/target.spm from cache at /root/.cache/huggingface/transformers/3332113748bc10131e394bb9ab70e08568c44b60770ed44d6ea550036b19d8f6.57770ce3f0b5bfc6db507c5882a9745db20c599b6d1100687bc4e97160004dc3\n","loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-id/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/71bd14915dcb9021df18a582b93a2eb6ebad9799c0b4dbee1cb83491d4587842.599a79c21ebfe6215ddc7bab4b2ade3c9f61f44f2c0e8b56fc3cf406565f87dc\n","loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-id/resolve/main/target_vocab.json from cache at None\n","loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-id/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/dbd2a982cdb3cf511e41bbcdb4d54e6d5c3506588f267d991c04652cda0ac62b.f1c5fd9548d09ba9e775cd1f755bd2087835fc89fcf0a366c734c388e050b8d4\n","loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-id/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-id/resolve/main/special_tokens_map.json from cache at None\n","loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-en-id/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/4d62c643c511f7fd504d5b8b9fe3e6ffb52b5b4cb4873de79090b34bdca69b37.78724ce53ce73bdd9784bb662a52f86d95686bc90e3b663d223271a92e76786f\n","Model config MarianConfig {\n","  \"_name_or_path\": \"Helsinki-NLP/opus-mt-en-id\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"swish\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"MarianMTModel\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bad_words_ids\": [\n","    [\n","      54795\n","    ]\n","  ],\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 512,\n","  \"decoder_attention_heads\": 8,\n","  \"decoder_ffn_dim\": 2048,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 54795,\n","  \"decoder_vocab_size\": 54796,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 8,\n","  \"encoder_ffn_dim\": 2048,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 0,\n","  \"forced_eos_token_id\": 0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_length\": 512,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"marian\",\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": false,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 54795,\n","  \"scale_embedding\": true,\n","  \"share_encoder_decoder_embeddings\": true,\n","  \"static_position_embeddings\": true,\n","  \"transformers_version\": \"4.18.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 54796\n","}\n","\n"]}],"source":["# model_t5 = \"t5-small\"\n","# from transformers import AutoTokenizer\n","# tokenizer = AutoTokenizer.from_pretrained(model_marianMT,use_fast=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["256966a30b8b4634a469aaa71b3d4240","3623c6c7cfb84ebb8b26edf587e267e6","1ef91de2278b495391e58a0b9cbd32a8","7ceba01948ac447d9a6f2fad4cc905e0","51091fb09afa45f0ac01e753499d6104","5b1589c2037443029a7662e230b2832f","5ccdf08ab63c46d29ce8ba4782bf1b79","f30902ba5fcc49fa901c82f7ba341e1d","41c3c823ccf047f2a23dbabdf862b6de","72685051ee2041799514c788be759a13","7d38f289999f45c69208cb7d4f7fda09","3e358edef31f406595b539ba3938c44d","9b471bf694174f7daa99c0542bed8e45","d7a58349ebf34a3b9e215706a89d4d22","fd8c92f161974e449ecd95d17cb8ab10","3ccbaf755eb14172a75445a4cd35b168","90be442142f44b1ea889b789f9111c9a","1c2a7985312f4aba8944cb6349010ebb","3c6819511d1a47bda9de766661fbbb52","20d52570cf744717bc23a4af4d7ad400","8fab9f18082c475ebf2a960fb60f9f8a","2c425e4123b247e08b807a31dc8ee390"]},"executionInfo":{"elapsed":1835992,"status":"ok","timestamp":1653288251918,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"NlaUTEJerexC","outputId":"cd635812-632a-4736-bce6-e76c45a36b62"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"256966a30b8b4634a469aaa71b3d4240","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/7415 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3e358edef31f406595b539ba3938c44d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1854 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["prefix = \"\" #for mBART and MarianMT\n","max_input_length = 128\n","max_target_length = 128\n","source_lang = \"id\"\n","target_lang = \"en\"\n","def preprocess_function(examples):\n","   inputs = [prefix + ex[source_lang] for ex in examples[\"translation\"]]\n","   targets = [ex[target_lang] for ex in examples[\"translation\"]]\n","   model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n","   # Setup the tokenizer for targets\n","   with tokenizer.as_target_tokenizer():\n","       labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n","   model_inputs[\"labels\"] = labels[\"input_ids\"]\n","   return model_inputs\n","tokenized_datasets = train_test.map(preprocess_function, batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C7vGxw0X6dZO"},"outputs":[],"source":["tokenized_datasets = tokenized_datasets.remove_columns(train_test[\"train\"].column_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gpl5MW97r5DC"},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-m-TwsOI0vWw"},"outputs":[],"source":["small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(280000))\n","small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(70000))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":98,"referenced_widgets":["fd6b05ecd12f402fa0aca80f48c96a4c","9fc728c8b9654a43871884c7ae012fac","39eb70430aa3440eb2977bb2ea4ca913","e89c7cc6bcb44202944421cf6bb71a3a","e765d932455a46e8b210328a9a9f22ae","64b7dcc3f40d4269987588cd56845b60","7da6434900d3437494013cb7546b0d11","b68930dd502144209fa1388882f1def0","9f13073e7bba46b3a981fe54faaa6dc6","f7f275e6f6c54b52a0b177aa555de2b7","a047892cbd5d42339837a1ff6769bb2f","5c493b8aa2d747b99c167557beee9d75","9c753322cac042f1b8d917f666025521","47a51c232dff4131bc4c9d1c53c0f426","2806aa1f76244d2c896cb9aea9f05fc9","e9478b14d3e5486f81acc4500d73896e","396b056c5f584f728b7899714e9d5a47","9804f6f02ba34a30a23dd12c35d3bfd5","8155324cc00c4118913e12bd8fd7b115","14c2d57f5e654eb1b5bfdf00982fe26e","9b12d916a54744e69287244246704233","f92b9ae1c8fa49daaf773e5d08576422"]},"executionInfo":{"elapsed":140767,"status":"ok","timestamp":1651978580029,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"pWLMTnuvkrJb","outputId":"09d701d0-7ca4-4dbf-af9a-58fe638c880a"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd6b05ecd12f402fa0aca80f48c96a4c","version_major":2,"version_minor":0},"text/plain":["Creating CSV from Arrow format:   0%|          | 0/35 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c493b8aa2d747b99c167557beee9d75","version_major":2,"version_minor":0},"text/plain":["Creating CSV from Arrow format:   0%|          | 0/35 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["41210513"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# path= 'drive/MyDrive/offline/Data/nlp2/en-id.txt/'\n","# small_train_dataset.to_csv(str(path+'small_train_dataset.csv'), index=False)\n","# small_eval_dataset.to_csv(str(path+'small_eval_dataset.csv'), index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6878,"status":"ok","timestamp":1653288261263,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"IoHsQ0wxnNnm","outputId":"17e596ac-caf2-431e-f715-e4123b91708e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/models/marian/tokenization_marian.py:196: UserWarning: Recommended: pip install sacremoses.\n","  warnings.warn(\"Recommended: pip install sacremoses.\")\n"]},{"data":{"text/plain":["['The government reported an addition of 247 new cases of Covid-19 in the last 24 hours.']"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import MarianMTModel, MarianTokenizer\n","src_text = ['Pemerintah melaporkan penambahan 247 kasus baru Covid-19 dalam 24 jam terakhir. Penambahan kasus baru itu tersebar di 20 provinsi.']\n","tokenizer = MarianTokenizer.from_pretrained(model_marianMT)\n","model = MarianMTModel.from_pretrained(model_marianMT)\n","translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True))\n","[tokenizer.decode(t, skip_special_tokens=True) for t in translated]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d6yG7AVN0K3H"},"outputs":[],"source":["model = AutoModelForSeq2SeqLM.from_pretrained(model_marianMT)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NAADqjtxP7g1"},"outputs":[],"source":["# from transformers import MBartForConditionalGeneration\n","# model = MBartForConditionalGeneration.from_pretrained(model_mbart)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8yKWyY9_P7oN"},"outputs":[],"source":["# from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","# model = AutoModelForSeq2SeqLM.from_pretrained(model_t5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_8D4-As1Ore"},"outputs":[],"source":["# model.split(\"/\")[-1]"]},{"cell_type":"markdown","metadata":{"id":"J57XK02Jfudv"},"source":["### Original Specification"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":201,"status":"ok","timestamp":1653103022992,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"ZM36SfqG0tMN","outputId":"98539e8d-af36-40b0-ecb5-883d04aeed93"},"outputs":[{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}],"source":["batch_size = 16\n","model_name = \"MarianMT\"\n","args = Seq2SeqTrainingArguments(\n","   f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n","   evaluation_strategy = \"epoch\",\n","   learning_rate=3e-5,  #2e-5,  #5e-4, #2e-5, #1e-2,\n","   per_device_train_batch_size=batch_size,\n","   per_device_eval_batch_size=batch_size,\n","   weight_decay=0.02,\n","   save_total_limit=3,\n","   num_train_epochs=2,\n","   predict_with_generate=True,\n","   optim=\"adamw_torch\"   \n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DDd__AyZ1FZQ"},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1416,"status":"ok","timestamp":1653103039006,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"BdBGfnV03qJP","outputId":"dfb5aef6-bae6-4e89-f68e-ccca7fb882fe"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}],"source":["import numpy as np\n","from datasets import load_metric\n","metric = load_metric(\"sacrebleu\")\n","meteor = load_metric('meteor')\n","\n","def postprocess_text(preds, labels):\n","   preds = [pred.strip() for pred in preds]\n","   labels = [[label.strip()] for label in labels]\n","   return preds, labels\n","\n","def compute_metrics(eval_preds):\n","   preds, labels = eval_preds\n","   if isinstance(preds, tuple):\n","       preds = preds[0]\n","   decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","   # Replace -100 in the labels as we can't decode them.\n","   labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","   decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","   # Some simple post-processing\n","   decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","   result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n","   meteor_result = meteor.compute(predictions=decoded_preds, references=decoded_labels)\n","   prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","   result = {'bleu' : result['score']}\n","   result[\"gen_len\"] = np.mean(prediction_lens)\n","   result[\"meteor\"] = meteor_result[\"meteor\"]\n","   result = {k: round(v, 4) for k, v in result.items()}\n","   return result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":14425124,"status":"ok","timestamp":1653096316706,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"k3yfkmRV3v5i","outputId":"f3dfd5e0-7d1c-44c3-a561-89a9d178b9be"},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 280000\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 35000\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='35000' max='35000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [35000/35000 4:00:24, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","      <th>Meteor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.267900</td>\n","      <td>1.144836</td>\n","      <td>41.247900</td>\n","      <td>9.240600</td>\n","      <td>0.386100</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.040700</td>\n","      <td>1.137484</td>\n","      <td>41.714400</td>\n","      <td>9.263400</td>\n","      <td>0.387400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-500/special_tokens_map.json\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-1000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-1000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-1000/special_tokens_map.json\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-1500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-1500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-1500/special_tokens_map.json\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-2000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-2000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-2000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-2500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-2500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-2500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-1000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-3000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-3000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-3000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-1500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-3500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-3500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-3500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-2000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-4000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-4000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-4000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-2500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-4500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-4500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-4500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-4500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-3000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-5000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-5000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-5000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-5000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-3500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-5500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-5500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-5500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-5500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-5500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-4000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-6000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-6000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-6000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-6000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-6000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-4500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-6500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-6500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-6500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-6500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-6500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-5000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-7000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-7000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-7000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-7000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-7000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-5500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-7500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-7500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-7500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-7500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-7500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-6000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-8000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-8000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-8000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-8000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-8000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-6500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-8500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-8500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-8500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-8500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-8500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-7000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-9000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-9000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-9000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-9000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-9000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-7500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-9500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-9500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-9500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-9500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-9500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-8000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-10000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-10000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-10000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-10000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-10000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-8500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-10500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-10500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-10500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-10500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-10500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-9000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-11000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-11000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-11000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-11000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-11000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-9500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-11500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-11500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-11500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-11500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-11500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-10000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-12000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-12000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-12000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-12000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-12000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-10500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-12500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-12500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-12500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-12500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-12500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-11000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-13000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-13000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-13000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-13000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-13000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-11500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-13500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-13500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-13500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-13500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-13500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-12000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-14000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-14000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-14000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-14000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-14000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-12500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-14500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-14500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-14500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-14500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-14500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-13000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-15000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-15000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-15000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-15000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-15000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-13500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-15500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-15500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-15500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-15500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-15500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-14000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-16000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-16000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-16000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-16000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-16000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-14500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-16500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-16500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-16500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-16500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-16500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-15000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-17000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-17000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-17000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-17000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-17000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-15500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-17500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-17500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-17500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-17500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-17500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-16000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 70000\n","  Batch size = 16\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-18000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-18000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-18000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-18000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-18000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-16500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-18500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-18500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-18500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-18500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-18500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-17000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-19000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-19000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-19000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-19000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-19000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-17500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-19500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-19500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-19500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-19500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-19500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-18000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-20000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-20000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-20000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-20000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-20000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-18500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-20500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-20500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-20500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-20500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-20500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-19000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-21000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-21000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-21000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-21000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-21000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-19500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-21500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-21500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-21500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-21500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-21500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-20000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-22000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-22000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-22000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-22000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-22000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-20500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-22500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-22500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-22500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-22500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-22500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-21000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-23000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-23000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-23000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-23000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-23000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-21500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-23500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-23500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-23500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-23500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-23500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-22000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-24000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-24000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-24000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-24000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-24000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-22500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-24500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-24500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-24500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-24500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-24500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-23000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-25000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-25000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-25000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-25000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-25000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-23500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-25500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-25500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-25500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-25500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-25500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-24000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-26000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-26000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-26000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-26000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-26000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-24500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-26500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-26500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-26500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-26500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-26500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-25000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-27000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-27000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-27000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-27000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-27000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-25500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-27500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-27500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-27500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-27500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-27500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-26000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-28000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-28000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-28000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-28000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-28000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-26500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-28500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-28500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-28500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-28500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-28500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-27000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-29000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-29000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-29000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-29000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-29000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-27500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-29500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-29500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-29500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-29500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-29500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-28000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-30000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-30000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-30000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-30000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-30000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-28500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-30500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-30500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-30500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-30500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-30500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-29000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-31000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-31000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-31000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-31000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-31000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-29500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-31500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-31500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-31500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-31500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-31500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-30000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-32000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-32000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-32000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-32000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-32000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-30500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-32500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-32500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-32500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-32500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-32500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-31000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-33000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-33000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-33000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-33000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-33000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-31500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-33500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-33500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-33500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-33500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-33500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-32000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-34000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-34000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-34000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-34000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-34000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-32500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-34500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-34500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-34500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-34500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-34500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-33000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-35000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-35000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-35000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-35000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-35000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-33500] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 70000\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"data":{"text/plain":["TrainOutput(global_step=35000, training_loss=1.1433472900390624, metrics={'train_runtime': 14424.6111, 'train_samples_per_second': 38.823, 'train_steps_per_second': 2.426, 'total_flos': 2852483849256960.0, 'train_loss': 1.1433472900390624, 'epoch': 2.0})"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["# using learning_rate=3e-5 and weight_decay=0.01\n","trainer = Seq2SeqTrainer(\n","   model,\n","   args,\n","   train_dataset=small_train_dataset,\n","   eval_dataset=small_eval_dataset,\n","   data_collator=data_collator,\n","   tokenizer=tokenizer, \n","   compute_metrics=compute_metrics, \n",")\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6582527,"status":"error","timestamp":1653102975365,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"dVzPke-HOE8X","outputId":"4704c2d8-4926-4cba-f0eb-250e5eb794dc"},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 280000\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 35000\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='23691' max='35000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [23691/35000 1:49:41 < 52:22, 3.60 it/s, Epoch 1.35/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","      <th>Meteor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.172200</td>\n","      <td>1.284279</td>\n","      <td>39.163000</td>\n","      <td>9.499200</td>\n","      <td>0.378500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-34000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-1000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-1000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-1000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-34500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-1500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-1500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-1500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-35000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-2000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-2000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-2000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-2500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-2500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-2500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-1000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-3000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-3000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-3000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-1500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-3500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-3500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-3500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-2000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-4000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-4000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-4000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-2500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-4500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-4500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-4500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-4500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-3000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-5000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-5000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-5000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-5000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-3500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-5500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-5500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-5500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-5500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-5500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-4000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-6000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-6000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-6000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-6000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-6000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-4500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-6500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-6500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-6500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-6500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-6500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-5000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-7000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-7000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-7000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-7000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-7000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-5500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-7500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-7500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-7500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-7500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-7500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-6000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-8000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-8000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-8000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-8000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-8000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-6500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-8500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-8500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-8500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-8500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-8500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-7000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-9000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-9000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-9000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-9000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-9000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-7500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-9500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-9500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-9500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-9500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-9500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-8000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-10000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-10000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-10000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-10000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-10000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-8500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-10500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-10500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-10500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-10500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-10500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-9000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-11000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-11000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-11000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-11000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-11000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-9500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-11500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-11500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-11500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-11500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-11500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-10000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-12000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-12000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-12000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-12000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-12000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-10500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-12500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-12500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-12500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-12500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-12500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-11000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-13000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-13000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-13000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-13000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-13000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-11500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-13500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-13500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-13500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-13500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-13500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-12000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-14000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-14000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-14000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-14000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-14000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-12500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-14500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-14500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-14500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-14500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-14500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-13000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-15000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-15000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-15000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-15000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-15000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-13500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-15500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-15500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-15500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-15500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-15500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-14000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-16000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-16000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-16000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-16000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-16000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-14500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-16500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-16500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-16500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-16500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-16500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-15000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-17000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-17000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-17000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-17000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-17000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-15500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-17500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-17500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-17500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-17500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-17500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-16000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 70000\n","  Batch size = 16\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-18000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-18000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-18000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-18000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-18000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-16500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-18500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-18500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-18500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-18500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-18500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-17000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-19000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-19000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-19000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-19000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-19000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-17500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-19500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-19500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-19500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-19500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-19500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-18000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-20000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-20000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-20000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-20000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-20000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-18500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-20500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-20500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-20500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-20500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-20500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-19000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-21000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-21000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-21000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-21000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-21000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-19500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-21500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-21500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-21500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-21500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-21500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-20000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-22000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-22000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-22000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-22000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-22000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-20500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-22500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-22500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-22500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-22500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-22500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-21000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-23000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-23000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-23000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-23000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-23000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-21500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-23500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-23500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-23500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-23500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-23500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-22000] due to args.save_total_limit\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-5d7154b23ad5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m    \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         )\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1552\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2199\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2200\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2201\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# using learning_rate=4e-5 and weight_decay=0.01\n","trainer = Seq2SeqTrainer(\n","   model,\n","   args,\n","   train_dataset=small_train_dataset,\n","   eval_dataset=small_eval_dataset,\n","   data_collator=data_collator,\n","   tokenizer=tokenizer, \n","   compute_metrics=compute_metrics, \n",")\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":5873581,"status":"error","timestamp":1653108964625,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"KeWFp4t7nxn3","outputId":"90abadf0-62cf-4977-c30d-8edf0dcbb9bd"},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 280000\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 35000\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='21501' max='35000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [21501/35000 1:37:52 < 1:01:27, 3.66 it/s, Epoch 1.23/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","      <th>Meteor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.961600</td>\n","      <td>1.402184</td>\n","      <td>38.120000</td>\n","      <td>9.502200</td>\n","      <td>0.374400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-22500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-1000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-1000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-1000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-23000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-1500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-1500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-1500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-23500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-2000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-2000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-2000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-2500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-2500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-2500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-1000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-3000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-3000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-3000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-1500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-3500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-3500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-3500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-2000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-4000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-4000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-4000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-2500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-4500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-4500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-4500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-4500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-3000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-5000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-5000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-5000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-5000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-3500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-5500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-5500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-5500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-5500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-5500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-4000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-6000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-6000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-6000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-6000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-6000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-4500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-6500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-6500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-6500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-6500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-6500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-5000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-7000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-7000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-7000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-7000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-7000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-5500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-7500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-7500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-7500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-7500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-7500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-6000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-8000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-8000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-8000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-8000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-8000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-6500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-8500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-8500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-8500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-8500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-8500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-7000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-9000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-9000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-9000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-9000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-9000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-7500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-9500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-9500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-9500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-9500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-9500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-8000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-10000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-10000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-10000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-10000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-10000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-8500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-10500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-10500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-10500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-10500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-10500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-9000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-11000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-11000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-11000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-11000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-11000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-9500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-11500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-11500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-11500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-11500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-11500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-10000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-12000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-12000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-12000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-12000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-12000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-10500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-12500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-12500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-12500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-12500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-12500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-11000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-13000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-13000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-13000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-13000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-13000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-11500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-13500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-13500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-13500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-13500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-13500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-12000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-14000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-14000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-14000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-14000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-14000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-12500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-14500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-14500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-14500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-14500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-14500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-13000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-15000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-15000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-15000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-15000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-15000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-13500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-15500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-15500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-15500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-15500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-15500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-14000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-16000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-16000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-16000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-16000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-16000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-14500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-16500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-16500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-16500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-16500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-16500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-15000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-17000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-17000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-17000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-17000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-17000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-15500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-17500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-17500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-17500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-17500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-17500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-16000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 70000\n","  Batch size = 16\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-18000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-18000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-18000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-18000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-18000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-16500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-18500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-18500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-18500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-18500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-18500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-17000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-19000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-19000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-19000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-19000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-19000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-17500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-19500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-19500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-19500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-19500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-19500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-18000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-20000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-20000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-20000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-20000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-20000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-18500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-20500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-20500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-20500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-20500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-20500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-19000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-21000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-21000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-21000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-21000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-21000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-19500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-21500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-21500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-21500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-21500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-21500/special_tokens_map.json\n"]},{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-f68cd3001cde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m    \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         )\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1627\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1800\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m             \u001b[0;31m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOPTIMIZER_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1903\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaught_warnings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSCHEDULER_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:300] . unexpected pos 51200 vs 51120"]}],"source":["# using learning_rate=3e-5 and weight_decay=0.02\n","trainer = Seq2SeqTrainer(\n","   model,\n","   args,\n","   train_dataset=small_train_dataset,\n","   eval_dataset=small_eval_dataset,\n","   data_collator=data_collator,\n","   tokenizer=tokenizer, \n","   compute_metrics=compute_metrics, \n",")\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"I9TMcNBL-zUg"},"source":["#### Learning Rate = 3e-5, weight decay = 0.01 and optim = adamw_torch, batch_size =32  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2YNzy2SC-Qwm"},"outputs":[],"source":["batch_size = 32\n","model_name = \"MarianMT\"\n","args = Seq2SeqTrainingArguments(\n","   f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n","   evaluation_strategy = \"epoch\",\n","   learning_rate=3e-5,  #2e-5,  #5e-4, #2e-5, #1e-2,\n","   per_device_train_batch_size=batch_size,\n","   per_device_eval_batch_size=batch_size,\n","   weight_decay=0.01,\n","   save_total_limit=3,\n","   num_train_epochs=2,\n","   predict_with_generate=True,\n","   optim=\"adamw_torch\"   \n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JMja1ttt-doe"},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":183,"referenced_widgets":["d87144d2edff4c59a4455198d5402f1c","5b6c3365cbc2406893255fc2b6a76a8c","dba30f2902184678a6bb614a2c4fb4fc","7ecdc8c0248d420ba27f9f9c70999f16","1709b55f984e423fad8ef89427282ddc","339efe75bbc243d9ac88a2436064b652","75d2a7dafae0431f809a903863b99d5c","cb441a0a9247425c944d58fd9831ce9e","24dbd44d39d848abba46588288e8716b","5c38bb417d7845169a27ac1b45a8a838","9eb2fa19d6e4483d9ac60238283a20dd","c733364ded9142c1b5893a3c2a03da58","dcb7fa7499c94fa2b0e2b033c7852db1","1fac790318e342bfa20046ebc52e99ea","e72fc4dda04d4dfeabc6360bf884b372","dd87f8ad032340e1aa8efeed1b7e36eb","60bc7b76baf74712868269885965fbd8","25ca514345764040bd04a0a442b9635e","07b81ca901144742b4b0c53ca1b9fc11","7a4e0da45aee422e97ba6ed2f4709b22","7c4f1052b7454cd787034d019f654294","7e24d8494b2b432d9e2085547bac86f2"]},"executionInfo":{"elapsed":3350,"status":"ok","timestamp":1653140489587,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"XpHvlhry-drU","outputId":"a94e24af-88d8-46a6-9570-bc4b6a582e40"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d87144d2edff4c59a4455198d5402f1c","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c733364ded9142c1b5893a3c2a03da58","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"]}],"source":["import numpy as np\n","from datasets import load_metric\n","metric = load_metric(\"sacrebleu\")\n","meteor = load_metric('meteor')\n","\n","def postprocess_text(preds, labels):\n","   preds = [pred.strip() for pred in preds]\n","   labels = [[label.strip()] for label in labels]\n","   return preds, labels\n","\n","def compute_metrics(eval_preds):\n","   preds, labels = eval_preds\n","   if isinstance(preds, tuple):\n","       preds = preds[0]\n","   decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","   # Replace -100 in the labels as we can't decode them.\n","   labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","   decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","   # Some simple post-processing\n","   decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","   result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n","   meteor_result = meteor.compute(predictions=decoded_preds, references=decoded_labels)\n","   prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","   result = {'bleu' : result['score']}\n","   result[\"gen_len\"] = np.mean(prediction_lens)\n","   result[\"meteor\"] = meteor_result[\"meteor\"]\n","   result = {k: round(v, 4) for k, v in result.items()}\n","   return result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":9472986,"status":"ok","timestamp":1653149976921,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"Hbdgjnaq-eAl","outputId":"6ccade9d-8a40-4a3a-c3c9-f3490b9e5866"},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 280000\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 17500\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='17500' max='17500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [17500/17500 2:37:52, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","      <th>Meteor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.178400</td>\n","      <td>1.083796</td>\n","      <td>42.553800</td>\n","      <td>9.030900</td>\n","      <td>0.390300</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.020100</td>\n","      <td>1.077685</td>\n","      <td>42.791300</td>\n","      <td>9.099600</td>\n","      <td>0.391500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-500/special_tokens_map.json\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-1000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-1000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-1000/special_tokens_map.json\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-1500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-1500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-1500/special_tokens_map.json\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-2000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-2000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-2000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-2500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-2500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-2500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-1000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-3000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-3000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-3000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-1500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-3500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-3500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-3500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-2000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-4000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-4000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-4000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-2500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-4500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-4500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-4500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-4500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-3000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-5000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-5000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-5000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-5000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-3500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-5500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-5500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-5500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-5500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-5500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-4000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-6000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-6000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-6000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-6000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-6000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-4500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-6500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-6500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-6500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-6500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-6500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-5000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-7000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-7000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-7000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-7000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-7000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-5500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-7500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-7500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-7500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-7500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-7500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-6000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-8000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-8000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-8000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-8000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-8000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-6500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-8500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-8500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-8500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-8500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-8500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-7000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 70000\n","  Batch size = 32\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-9000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-9000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-9000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-9000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-9000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-7500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-9500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-9500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-9500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-9500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-9500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-8000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-10000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-10000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-10000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-10000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-10000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-8500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-10500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-10500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-10500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-10500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-10500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-9000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-11000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-11000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-11000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-11000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-11000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-9500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-11500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-11500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-11500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-11500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-11500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-10000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-12000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-12000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-12000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-12000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-12000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-10500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-12500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-12500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-12500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-12500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-12500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-11000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-13000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-13000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-13000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-13000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-13000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-11500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-13500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-13500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-13500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-13500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-13500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-12000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-14000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-14000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-14000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-14000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-14000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-12500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-14500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-14500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-14500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-14500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-14500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-13000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-15000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-15000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-15000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-15000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-15000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-13500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-15500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-15500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-15500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-15500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-15500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-14000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-16000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-16000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-16000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-16000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-16000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-14500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-16500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-16500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-16500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-16500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-16500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-15000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-17000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-17000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-17000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-17000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-17000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-15500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-17500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-17500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-17500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-17500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-17500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-16000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 70000\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"data":{"text/plain":["TrainOutput(global_step=17500, training_loss=1.1049403163364955, metrics={'train_runtime': 9472.5572, 'train_samples_per_second': 59.118, 'train_steps_per_second': 1.847, 'total_flos': 3396514470690816.0, 'train_loss': 1.1049403163364955, 'epoch': 2.0})"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# using learning_rate=3e-5 and weight_decay=0.01\n","trainer = Seq2SeqTrainer(\n","   model,\n","   args,\n","   train_dataset=small_train_dataset,\n","   eval_dataset=small_eval_dataset,\n","   data_collator=data_collator,\n","   tokenizer=tokenizer, \n","   compute_metrics=compute_metrics, \n",")\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"ZWgfcqExdPyq"},"source":["### Best Model: Learning Rate = 3e-5, weight decay = 0.01 and optim = adamw_torch, batch_size =32"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wOpPBBVjdPMW"},"outputs":[],"source":["batch_size = 32\n","model_name = \"MarianMT\"\n","args = Seq2SeqTrainingArguments(\n","   f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n","   evaluation_strategy = \"epoch\",\n","   learning_rate=3e-5,  #2e-5,  #5e-4, #2e-5, #1e-2,\n","   per_device_train_batch_size=batch_size,\n","   per_device_eval_batch_size=batch_size,\n","   weight_decay=0.01,\n","   save_total_limit=3,\n","   num_train_epochs=10,\n","   predict_with_generate=True,\n","   optim=\"adamw_torch\"   \n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RkA30UmydXVX"},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":185,"referenced_widgets":["2c6a243b447c47b288a0dde3ec5fb340","c4a0b4b39dcf4386924fe1ac8a0deabd","c3fdc10faa3044ea9125aa1c5af3eeee","c175afb9479948f49f12f4608e7215c8","cf3734747d92484f9f2908e88bbec7f0","ed8540c894d748988182d977ee7d3473","ac88d07ddb6540c48484a12767b3342f","8b2b543abd134dea91c8fe37a1b2360b","769da42e59fe4c97b8071f0d02c57ad8","f98080bce3284d3c85330aec979c7950","568e13b8470c4a88a17d4afc84943602","5daa18b25ed54b3aad8fdda8adf789c6","5724a4831c0f48d49982b0b9757f885e","7a8f80c46a774e06b2e212767094fe68","ef240b71b883479da040485ec84ceb1c","5689c3fa4f9a44a7aea9f40334cf1360","27aba90c01794d5a86e36bb57e888b94","94f6c20c3aff440ea17a7a5e3ad48ec0","016f7e86dff845a48de58489382ebe09","780a4e0580a746d29c1685b91865a1a2","f4fcc2f7d27047d1aba1521624bd5b8d","a8e7af530c784b838d3f8d6f956ead4c"]},"executionInfo":{"elapsed":3408,"status":"ok","timestamp":1653288267532,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"pSldf9JZdXYZ","outputId":"f86f815c-6e65-489d-fcde-9b202cf09f7e"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c6a243b447c47b288a0dde3ec5fb340","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5daa18b25ed54b3aad8fdda8adf789c6","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"]}],"source":["import numpy as np\n","from datasets import load_metric\n","metric = load_metric(\"sacrebleu\")\n","meteor = load_metric('meteor')\n","\n","def postprocess_text(preds, labels):\n","   preds = [pred.strip() for pred in preds]\n","   labels = [[label.strip()] for label in labels]\n","   return preds, labels\n","\n","def compute_metrics(eval_preds):\n","   preds, labels = eval_preds\n","   if isinstance(preds, tuple):\n","       preds = preds[0]\n","   decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","   # Replace -100 in the labels as we can't decode them.\n","   labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","   decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","   # Some simple post-processing\n","   decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","   result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n","   meteor_result = meteor.compute(predictions=decoded_preds, references=decoded_labels)\n","   prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","   result = {'bleu' : result['score']}\n","   result[\"gen_len\"] = np.mean(prediction_lens)\n","   result[\"meteor\"] = meteor_result[\"meteor\"]\n","   result = {k: round(v, 4) for k, v in result.items()}\n","   return result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"1ss-eWX-dXb2","outputId":"f9cfa9a9-c2f0-4b8b-ca45-a599b48a645b","executionInfo":{"status":"error","timestamp":1653333322841,"user_tz":240,"elapsed":251739,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"}}},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 280000\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 87500\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='78751' max='87500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [78751/87500 11:49:52 < 1:18:51, 1.85 it/s, Epoch 9/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","      <th>Meteor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.189700</td>\n","      <td>1.114373</td>\n","      <td>41.939900</td>\n","      <td>9.084200</td>\n","      <td>0.388100</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.074100</td>\n","      <td>1.132129</td>\n","      <td>41.727300</td>\n","      <td>9.082300</td>\n","      <td>0.387100</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.973100</td>\n","      <td>1.148730</td>\n","      <td>41.526700</td>\n","      <td>9.169300</td>\n","      <td>0.387000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.881200</td>\n","      <td>1.171077</td>\n","      <td>41.487700</td>\n","      <td>9.071700</td>\n","      <td>0.386000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.812200</td>\n","      <td>1.189171</td>\n","      <td>41.246100</td>\n","      <td>9.082900</td>\n","      <td>0.385400</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.742000</td>\n","      <td>1.209302</td>\n","      <td>40.980300</td>\n","      <td>9.097300</td>\n","      <td>0.384800</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.696700</td>\n","      <td>1.226081</td>\n","      <td>40.901100</td>\n","      <td>9.146400</td>\n","      <td>0.384200</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.660500</td>\n","      <td>1.239323</td>\n","      <td>40.764400</td>\n","      <td>9.135400</td>\n","      <td>0.383800</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='1966' max='2188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1966/2188 36:50 < 04:09, 0.89 it/s]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-500/special_tokens_map.json\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-1000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-1000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-1000/special_tokens_map.json\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-1500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-1500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-1500/special_tokens_map.json\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-2000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-2000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-2000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-2500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-2500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-2500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-1000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-3000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-3000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-3000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-1500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-3500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-3500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-3500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-2000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-4000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-4000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-4000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-2500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-4500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-4500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-4500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-4500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-3000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-5000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-5000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-5000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-5000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-3500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-5500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-5500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-5500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-5500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-5500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-4000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-6000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-6000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-6000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-6000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-6000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-4500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-6500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-6500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-6500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-6500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-6500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-5000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-7000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-7000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-7000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-7000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-7000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-5500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-7500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-7500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-7500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-7500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-7500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-6000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-8000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-8000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-8000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-8000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-8000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-6500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-8500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-8500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-8500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-8500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-8500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-7000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 70000\n","  Batch size = 32\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-9000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-9000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-9000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-9000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-9000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-7500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-9500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-9500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-9500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-9500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-9500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-8000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-10000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-10000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-10000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-10000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-10000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-8500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-10500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-10500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-10500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-10500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-10500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-9000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-11000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-11000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-11000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-11000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-11000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-9500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-11500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-11500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-11500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-11500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-11500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-10000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-12000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-12000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-12000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-12000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-12000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-10500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-12500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-12500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-12500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-12500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-12500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-11000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-13000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-13000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-13000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-13000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-13000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-11500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-13500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-13500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-13500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-13500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-13500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-12000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-14000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-14000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-14000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-14000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-14000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-12500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-14500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-14500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-14500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-14500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-14500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-13000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-15000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-15000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-15000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-15000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-15000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-13500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-15500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-15500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-15500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-15500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-15500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-14000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-16000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-16000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-16000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-16000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-16000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-14500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-16500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-16500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-16500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-16500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-16500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-15000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-17000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-17000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-17000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-17000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-17000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-15500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-17500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-17500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-17500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-17500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-17500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-16000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 70000\n","  Batch size = 32\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-18000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-18000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-18000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-18000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-18000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-16500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-18500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-18500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-18500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-18500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-18500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-17000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-19000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-19000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-19000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-19000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-19000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-17500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-19500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-19500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-19500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-19500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-19500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-18000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-20000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-20000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-20000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-20000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-20000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-18500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-20500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-20500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-20500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-20500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-20500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-19000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-21000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-21000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-21000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-21000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-21000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-19500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-21500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-21500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-21500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-21500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-21500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-20000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-22000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-22000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-22000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-22000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-22000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-20500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-22500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-22500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-22500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-22500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-22500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-21000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-23000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-23000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-23000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-23000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-23000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-21500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-23500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-23500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-23500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-23500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-23500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-22000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-24000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-24000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-24000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-24000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-24000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-22500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-24500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-24500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-24500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-24500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-24500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-23000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-25000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-25000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-25000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-25000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-25000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-23500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-25500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-25500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-25500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-25500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-25500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-24000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-26000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-26000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-26000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-26000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-26000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-24500] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 70000\n","  Batch size = 32\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-26500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-26500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-26500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-26500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-26500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-25000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-27000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-27000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-27000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-27000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-27000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-25500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-27500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-27500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-27500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-27500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-27500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-26000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-28000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-28000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-28000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-28000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-28000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-26500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-28500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-28500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-28500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-28500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-28500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-27000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-29000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-29000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-29000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-29000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-29000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-27500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-29500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-29500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-29500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-29500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-29500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-28000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-30000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-30000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-30000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-30000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-30000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-28500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-30500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-30500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-30500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-30500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-30500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-29000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-31000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-31000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-31000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-31000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-31000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-29500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-31500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-31500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-31500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-31500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-31500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-30000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-32000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-32000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-32000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-32000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-32000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-30500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-32500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-32500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-32500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-32500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-32500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-31000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-33000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-33000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-33000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-33000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-33000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-31500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-33500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-33500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-33500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-33500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-33500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-32000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-34000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-34000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-34000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-34000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-34000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-32500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-34500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-34500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-34500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-34500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-34500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-33000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-35000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-35000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-35000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-35000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-35000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-33500] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 70000\n","  Batch size = 32\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-35500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-35500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-35500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-35500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-35500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-34000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-36000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-36000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-36000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-36000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-36000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-34500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-36500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-36500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-36500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-36500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-36500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-35000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-37000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-37000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-37000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-37000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-37000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-35500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-37500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-37500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-37500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-37500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-37500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-36000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-38000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-38000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-38000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-38000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-38000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-36500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-38500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-38500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-38500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-38500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-38500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-37000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-39000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-39000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-39000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-39000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-39000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-37500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-39500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-39500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-39500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-39500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-39500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-38000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-40000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-40000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-40000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-40000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-40000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-38500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-40500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-40500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-40500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-40500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-40500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-39000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-41000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-41000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-41000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-41000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-41000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-39500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-41500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-41500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-41500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-41500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-41500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-40000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-42000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-42000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-42000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-42000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-42000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-40500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-42500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-42500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-42500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-42500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-42500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-41000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-43000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-43000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-43000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-43000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-43000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-41500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-43500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-43500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-43500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-43500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-43500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-42000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 70000\n","  Batch size = 32\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-44000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-44000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-44000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-44000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-44000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-42500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-44500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-44500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-44500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-44500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-44500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-43000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-45000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-45000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-45000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-45000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-45000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-43500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-45500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-45500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-45500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-45500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-45500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-44000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-46000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-46000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-46000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-46000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-46000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-44500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-46500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-46500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-46500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-46500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-46500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-45000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-47000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-47000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-47000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-47000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-47000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-45500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-47500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-47500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-47500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-47500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-47500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-46000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-48000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-48000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-48000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-48000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-48000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-46500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-48500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-48500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-48500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-48500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-48500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-47000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-49000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-49000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-49000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-49000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-49000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-47500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-49500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-49500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-49500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-49500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-49500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-48000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-50000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-50000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-50000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-50000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-50000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-48500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-50500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-50500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-50500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-50500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-50500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-49000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-51000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-51000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-51000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-51000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-51000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-49500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-51500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-51500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-51500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-51500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-51500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-50000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-52000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-52000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-52000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-52000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-52000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-50500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-52500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-52500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-52500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-52500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-52500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-51000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 70000\n","  Batch size = 32\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-53000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-53000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-53000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-53000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-53000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-51500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-53500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-53500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-53500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-53500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-53500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-52000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-54000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-54000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-54000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-54000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-54000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-52500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-54500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-54500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-54500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-54500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-54500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-53000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-55000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-55000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-55000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-55000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-55000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-53500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-55500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-55500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-55500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-55500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-55500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-54000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-56000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-56000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-56000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-56000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-56000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-54500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-56500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-56500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-56500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-56500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-56500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-55000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-57000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-57000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-57000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-57000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-57000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-55500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-57500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-57500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-57500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-57500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-57500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-56000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-58000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-58000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-58000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-58000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-58000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-56500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-58500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-58500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-58500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-58500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-58500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-57000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-59000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-59000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-59000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-59000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-59000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-57500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-59500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-59500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-59500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-59500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-59500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-58000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-60000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-60000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-60000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-60000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-60000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-58500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-60500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-60500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-60500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-60500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-60500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-59000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-61000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-61000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-61000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-61000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-61000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-59500] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 70000\n","  Batch size = 32\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-61500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-61500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-61500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-61500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-61500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-60000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-62000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-62000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-62000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-62000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-62000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-60500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-62500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-62500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-62500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-62500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-62500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-61000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-63000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-63000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-63000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-63000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-63000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-61500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-63500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-63500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-63500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-63500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-63500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-62000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-64000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-64000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-64000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-64000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-64000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-62500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-64500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-64500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-64500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-64500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-64500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-63000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-65000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-65000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-65000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-65000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-65000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-63500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-65500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-65500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-65500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-65500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-65500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-64000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-66000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-66000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-66000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-66000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-66000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-64500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-66500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-66500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-66500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-66500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-66500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-65000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-67000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-67000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-67000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-67000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-67000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-65500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-67500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-67500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-67500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-67500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-67500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-66000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-68000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-68000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-68000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-68000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-68000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-66500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-68500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-68500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-68500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-68500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-68500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-67000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-69000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-69000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-69000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-69000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-69000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-67500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-69500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-69500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-69500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-69500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-69500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-68000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-70000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-70000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-70000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-70000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-70000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-68500] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 70000\n","  Batch size = 32\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-70500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-70500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-70500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-70500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-70500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-69000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-71000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-71000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-71000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-71000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-71000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-69500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-71500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-71500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-71500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-71500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-71500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-70000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-72000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-72000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-72000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-72000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-72000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-70500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-72500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-72500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-72500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-72500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-72500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-71000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-73000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-73000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-73000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-73000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-73000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-71500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-73500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-73500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-73500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-73500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-73500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-72000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-74000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-74000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-74000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-74000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-74000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-72500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-74500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-74500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-74500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-74500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-74500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-73000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-75000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-75000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-75000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-75000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-75000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-73500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-75500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-75500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-75500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-75500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-75500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-74000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-76000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-76000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-76000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-76000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-76000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-74500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-76500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-76500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-76500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-76500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-76500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-75000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-77000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-77000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-77000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-77000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-77000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-75500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-77500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-77500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-77500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-77500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-77500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-76000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-78000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-78000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-78000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-78000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-78000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-76500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-78500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-78500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-78500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-78500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-78500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-77000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 70000\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='78751' max='87500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [78751/87500 11:49:52 < 1:18:51, 1.85 it/s, Epoch 9/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","      <th>Meteor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.189700</td>\n","      <td>1.114373</td>\n","      <td>41.939900</td>\n","      <td>9.084200</td>\n","      <td>0.388100</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.074100</td>\n","      <td>1.132129</td>\n","      <td>41.727300</td>\n","      <td>9.082300</td>\n","      <td>0.387100</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.973100</td>\n","      <td>1.148730</td>\n","      <td>41.526700</td>\n","      <td>9.169300</td>\n","      <td>0.387000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.881200</td>\n","      <td>1.171077</td>\n","      <td>41.487700</td>\n","      <td>9.071700</td>\n","      <td>0.386000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.812200</td>\n","      <td>1.189171</td>\n","      <td>41.246100</td>\n","      <td>9.082900</td>\n","      <td>0.385400</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.742000</td>\n","      <td>1.209302</td>\n","      <td>40.980300</td>\n","      <td>9.097300</td>\n","      <td>0.384800</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.696700</td>\n","      <td>1.226081</td>\n","      <td>40.901100</td>\n","      <td>9.146400</td>\n","      <td>0.384200</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.660500</td>\n","      <td>1.239323</td>\n","      <td>40.764400</td>\n","      <td>9.135400</td>\n","      <td>0.383800</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='2179' max='2188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2179/2188 40:53 < 00:10, 0.89 it/s]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-c1249d7ab1a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m    \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         )\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1644\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1794\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1796\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer_seq2seq.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, max_length, num_beams)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_max_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_beams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_num_beams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     def predict(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2463\u001b[0m             \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2464\u001b[0m             \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2465\u001b[0;31m             \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2466\u001b[0m         )\n\u001b[1;32m   2467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2635\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2636\u001b[0m             \u001b[0minputs_decode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_inputs_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer_seq2seq.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m    177\u001b[0m         generated_tokens = self.model.generate(\n\u001b[1;32m    178\u001b[0m             \u001b[0mgeneration_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mgen_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# in case the batch is shorter than max length, the output should be padded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[1;32m   1352\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m             )\n\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2269\u001b[0m             \u001b[0mcur_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_len\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2271\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_done\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstopping_criteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2272\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msynced_gpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2273\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# using learning_rate=3e-5 and weight_decay=0.01\n","trainer = Seq2SeqTrainer(\n","   model,\n","   args,\n","   train_dataset=small_train_dataset,\n","   eval_dataset=small_eval_dataset,\n","   data_collator=data_collator,\n","   tokenizer=tokenizer, \n","   compute_metrics=compute_metrics, \n",")\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"StPC8oXKADd9"},"source":["#### Learning Rate = 3e-5, weight decay = 0.01 and optim = adamw_torch, batch_size=64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w0pD1aUd_5ue"},"outputs":[],"source":["batch_size = 64\n","model_name = \"MarianMT\"\n","args = Seq2SeqTrainingArguments(\n","   f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n","   evaluation_strategy = \"epoch\",\n","   learning_rate=3e-5,  #2e-5,  #5e-4, #2e-5, #1e-2,\n","   per_device_train_batch_size=batch_size,\n","   per_device_eval_batch_size=batch_size,\n","   weight_decay=0.01,\n","   save_total_limit=3,\n","   num_train_epochs=2,\n","   predict_with_generate=True,\n","   optim=\"adamw_torch\"   \n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F0ruNVJ8_5rA"},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1483,"status":"ok","timestamp":1653153066552,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"JhXaBgF__5x0","outputId":"dbd00280-909c-4124-e81d-273165fa4c02"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}],"source":["import numpy as np\n","from datasets import load_metric\n","metric = load_metric(\"sacrebleu\")\n","meteor = load_metric('meteor')\n","\n","def postprocess_text(preds, labels):\n","   preds = [pred.strip() for pred in preds]\n","   labels = [[label.strip()] for label in labels]\n","   return preds, labels\n","\n","def compute_metrics(eval_preds):\n","   preds, labels = eval_preds\n","   if isinstance(preds, tuple):\n","       preds = preds[0]\n","   decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","   # Replace -100 in the labels as we can't decode them.\n","   labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","   decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","   # Some simple post-processing\n","   decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","   result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n","   meteor_result = meteor.compute(predictions=decoded_preds, references=decoded_labels)\n","   prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","   result = {'bleu' : result['score']}\n","   result[\"gen_len\"] = np.mean(prediction_lens)\n","   result[\"meteor\"] = meteor_result[\"meteor\"]\n","   result = {k: round(v, 4) for k, v in result.items()}\n","   return result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":611569,"status":"error","timestamp":1653153678112,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"nBKjlct__50e","outputId":"a04d53ec-ee52-4384-982d-fdc8eb563d03"},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 280000\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 8750\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='4376' max='8750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4376/8750 09:51 < 09:51, 7.39 it/s, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-3000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-1000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-1000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-1000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-3500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-1500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-1500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-1500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-4000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-2000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-2000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-2000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-2500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-2500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-2500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-1000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-3000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-3000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-3000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-1500] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-3500\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-3500/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-3500/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-2000] due to args.save_total_limit\n","Saving model checkpoint to MarianMT-finetuned-id-to-en/checkpoint-4000\n","Configuration saved in MarianMT-finetuned-id-to-en/checkpoint-4000/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/checkpoint-4000/special_tokens_map.json\n","Deleting older checkpoint [MarianMT-finetuned-id-to-en/checkpoint-2500] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 70000\n","  Batch size = 64\n"]},{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-c1249d7ab1a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m    \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         )\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1644\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1794\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1796\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer_seq2seq.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, max_length, num_beams)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_max_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_beams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_num_beams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     def predict(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2463\u001b[0m             \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2464\u001b[0m             \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2465\u001b[0;31m             \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2466\u001b[0m         )\n\u001b[1;32m   2467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2635\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2636\u001b[0m             \u001b[0minputs_decode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_inputs_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer_seq2seq.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m    177\u001b[0m         generated_tokens = self.model.generate(\n\u001b[1;32m    178\u001b[0m             \u001b[0mgeneration_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mgen_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# in case the batch is shorter than max length, the output should be padded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[1;32m   1352\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m             )\n\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2261\u001b[0m             )\n\u001b[1;32m   2262\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"past\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2263\u001b[0;31m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"past\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reorder_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"past\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_in_generate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moutput_scores\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/marian/modeling_marian.py\u001b[0m in \u001b[0;36m_reorder_cache\u001b[0;34m(past, beam_idx)\u001b[0m\n\u001b[1;32m   1513\u001b[0m             \u001b[0;31m# cached cross_attention states don't have to be reordered -> they are always the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m             reordered_past += (\n\u001b[0;32m-> 1515\u001b[0;31m                 \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpast_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1516\u001b[0m             )\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreordered_past\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/marian/modeling_marian.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1513\u001b[0m             \u001b[0;31m# cached cross_attention states don't have to be reordered -> they are always the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m             reordered_past += (\n\u001b[0;32m-> 1515\u001b[0;31m                 \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpast_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1516\u001b[0m             )\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreordered_past\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 316.00 MiB (GPU 0; 15.78 GiB total capacity; 12.17 GiB already allocated; 312.75 MiB free; 13.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["# using learning_rate=3e-5 and weight_decay=0.01\n","trainer = Seq2SeqTrainer(\n","   model,\n","   args,\n","   train_dataset=small_train_dataset,\n","   eval_dataset=small_eval_dataset,\n","   data_collator=data_collator,\n","   tokenizer=tokenizer, \n","   compute_metrics=compute_metrics, \n",")\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"SGcvy_nJa-Xw"},"source":["### Saving "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YaMhmFaq4I_I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653333774864,"user_tz":240,"elapsed":744,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"}},"outputId":"d7dffb10-1fb3-410c-83b8-cac28c7c7d11"},"outputs":[{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to MarianMT-finetuned-id-to-en\n","Configuration saved in MarianMT-finetuned-id-to-en/config.json\n","Model weights saved in MarianMT-finetuned-id-to-en/pytorch_model.bin\n","tokenizer config file saved in MarianMT-finetuned-id-to-en/tokenizer_config.json\n","Special tokens file saved in MarianMT-finetuned-id-to-en/special_tokens_map.json\n"]}],"source":["trainer.save_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":251,"status":"ok","timestamp":1653333790058,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"q0_H4-Q1-W7-","outputId":"3e84edeb-024f-42b4-c941-9b63a07264be"},"outputs":[{"output_type":"stream","name":"stdout","text":["drive  MarianMT-finetuned-id-to-en  sample_data\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":145,"status":"ok","timestamp":1651364319464,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"9JSdkaUL90PW","outputId":"2f70d210-0476-4f82-8820-ecff1d0e10b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["MBart-finetuned-en-to-id/training_args.bin\n","MBart-finetuned-en-to-id/pytorch_model.bin\n","MBart-finetuned-en-to-id/tokenizer_config.json\n","MBart-finetuned-en-to-id/source.spm\n","MBart-finetuned-en-to-id/vocab.json\n","MBart-finetuned-en-to-id/special_tokens_map.json\n","MBart-finetuned-en-to-id/config.json\n","MBart-finetuned-en-to-id/target.spm\n","MBart-finetuned-en-to-id/runs/Apr30_21-00-28_2da5c548e99e/events.out.tfevents.1651352518.2da5c548e99e.1050.7\n","MBart-finetuned-en-to-id/runs/Apr30_21-00-28_2da5c548e99e/1651352518.7937372/events.out.tfevents.1651352518.2da5c548e99e.1050.8\n"]}],"source":["import os\n","for dirname, _, filenames in os.walk('MBart-finetuned-en-to-id'):\n","   for filename in filenames:\n","       print(os.path.join(dirname, filename))\n","\n"]},{"cell_type":"markdown","source":["### Use the fine tuned model for translation"],"metadata":{"id":"FVnvfNMSXcbp"}},{"cell_type":"code","source":["from transformers import MarianMTModel, MarianTokenizer\n","model_name = 'MarianMT-finetuned-id-to-en'\n","tokenizer = MarianTokenizer.from_pretrained(model_name)\n","model = MarianMTModel.from_pretrained(model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9JjOVp8_Xbkh","executionInfo":{"status":"ok","timestamp":1653333981917,"user_tz":240,"elapsed":2601,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"}},"outputId":"14d476fe-b1a3-43fa-860a-2d1b17857b6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Didn't find file MarianMT-finetuned-id-to-en/target_vocab.json. We won't load it.\n","Didn't find file MarianMT-finetuned-id-to-en/added_tokens.json. We won't load it.\n","loading file MarianMT-finetuned-id-to-en/source.spm\n","loading file MarianMT-finetuned-id-to-en/target.spm\n","loading file MarianMT-finetuned-id-to-en/vocab.json\n","loading file None\n","loading file MarianMT-finetuned-id-to-en/tokenizer_config.json\n","loading file None\n","loading file MarianMT-finetuned-id-to-en/special_tokens_map.json\n","/usr/local/lib/python3.7/dist-packages/transformers/models/marian/tokenization_marian.py:196: UserWarning: Recommended: pip install sacremoses.\n","  warnings.warn(\"Recommended: pip install sacremoses.\")\n","loading configuration file MarianMT-finetuned-id-to-en/config.json\n","Model config MarianConfig {\n","  \"_name_or_path\": \"Helsinki-NLP/opus-mt-id-en\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"swish\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"MarianMTModel\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bad_words_ids\": [\n","    [\n","      54795\n","    ]\n","  ],\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 512,\n","  \"decoder_attention_heads\": 8,\n","  \"decoder_ffn_dim\": 2048,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 54795,\n","  \"decoder_vocab_size\": 54796,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 8,\n","  \"encoder_ffn_dim\": 2048,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 0,\n","  \"forced_eos_token_id\": 0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_length\": 512,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"marian\",\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": false,\n","  \"num_beams\": 6,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 54795,\n","  \"scale_embedding\": true,\n","  \"share_encoder_decoder_embeddings\": true,\n","  \"static_position_embeddings\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.19.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 54796\n","}\n","\n","loading weights file MarianMT-finetuned-id-to-en/pytorch_model.bin\n","All model checkpoint weights were used when initializing MarianMTModel.\n","\n","All the weights of MarianMTModel were initialized from the model checkpoint at MarianMT-finetuned-id-to-en.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n"]}]},{"cell_type":"markdown","source":["Example 700"],"metadata":{"id":"CSTJrkpCYQQi"}},{"cell_type":"code","source":["src_text = ['aku sudah berada di sini berkali - kali , tapi aku tidak pernah melihat pohon suci di malam hari']\n","translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True))\n","[tokenizer.decode(t, skip_special_tokens=True) for t in translated]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uUyGwciEYSv6","executionInfo":{"status":"ok","timestamp":1653334045472,"user_tz":240,"elapsed":842,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"}},"outputId":"211a9562-6997-43c5-9971-6a1adf1f5eb6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"I've been here many times, but I've never seen a tree sacred at night\"]"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["Example 4002"],"metadata":{"id":"xdWEWm1RZHz3"}},{"cell_type":"code","source":["#aku masih mempercayai kalau aku dalam kontrol secara sadar akan tindakan - tindakanku .\n","src_text = ['aku masih mempercayai kalau aku dalam kontrol secara sadar akan tindakan - tindakanku.']\n","translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True))\n","[tokenizer.decode(t, skip_special_tokens=True) for t in translated]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pzn7H6tCYSyr","executionInfo":{"status":"ok","timestamp":1653334234776,"user_tz":240,"elapsed":513,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"}},"outputId":"fd7b7344-92e0-4788-dad4-f1db587981f8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"I still believe that I'm consciously aware of my actions.\"]"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3503,"status":"ok","timestamp":1651347547707,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"Qpw9z7No-naH","outputId":"014d07ab-524c-4f4a-e5de-997ec66eb3bb"},"outputs":[{"name":"stderr","output_type":"stream","text":["Didn't find file MarianMTModel-finetuned-en-to-id/target_vocab.json. We won't load it.\n","Didn't find file MarianMTModel-finetuned-en-to-id/added_tokens.json. We won't load it.\n","loading file MarianMTModel-finetuned-en-to-id/source.spm\n","loading file MarianMTModel-finetuned-en-to-id/target.spm\n","loading file MarianMTModel-finetuned-en-to-id/vocab.json\n","loading file None\n","loading file MarianMTModel-finetuned-en-to-id/tokenizer_config.json\n","loading file None\n","loading file MarianMTModel-finetuned-en-to-id/special_tokens_map.json\n","loading configuration file MarianMTModel-finetuned-en-to-id/config.json\n","Model config MarianConfig {\n","  \"_name_or_path\": \"Helsinki-NLP/opus-mt-en-id\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"swish\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"MarianMTModel\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bad_words_ids\": [\n","    [\n","      54795\n","    ]\n","  ],\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 512,\n","  \"decoder_attention_heads\": 8,\n","  \"decoder_ffn_dim\": 2048,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 54795,\n","  \"decoder_vocab_size\": 54796,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 8,\n","  \"encoder_ffn_dim\": 2048,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 0,\n","  \"forced_eos_token_id\": 0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_length\": 512,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"marian\",\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": false,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 54795,\n","  \"scale_embedding\": true,\n","  \"share_encoder_decoder_embeddings\": true,\n","  \"static_position_embeddings\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.18.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 54796\n","}\n","\n","loading weights file MarianMTModel-finetuned-en-to-id/pytorch_model.bin\n","All model checkpoint weights were used when initializing MarianMTModel.\n","\n","All the weights of MarianMTModel were initialized from the model checkpoint at MarianMTModel-finetuned-en-to-id.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n"]},{"data":{"text/plain":["['USA Today adalah surat kabar pasar menengah Amerika sehari-hari yang diterbitkan oleh pemilik kapal, Gannett, didirikan oleh Al Neuharth pada 15 September 1982.']"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import MarianMTModel, MarianTokenizer\n","src_text = ['USA Today is an American daily middle-market newspaper that is the flagship publication of its owner, Gannett. Founded by Al Neuharth on September 15, 1982.']\n","model_name = 'MarianMTModel-finetuned-en-to-id'\n","tokenizer = MarianTokenizer.from_pretrained(model_name)\n","model = MarianMTModel.from_pretrained(model_name)\n","translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True))\n","[tokenizer.decode(t, skip_special_tokens=True) for t in translated]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":168,"status":"ok","timestamp":1651365300425,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"l8rnWtODCRju","outputId":"c4a9409d-e3a5-4154-e088-046b1dc8b81a"},"outputs":[{"name":"stdout","output_type":"stream","text":["MBart-finetuned-en-to-id/training_args.bin\n","MBart-finetuned-en-to-id/pytorch_model.bin\n","MBart-finetuned-en-to-id/tokenizer_config.json\n","MBart-finetuned-en-to-id/source.spm\n","MBart-finetuned-en-to-id/vocab.json\n","MBart-finetuned-en-to-id/special_tokens_map.json\n","MBart-finetuned-en-to-id/config.json\n","MBart-finetuned-en-to-id/target.spm\n","MBart-finetuned-en-to-id/runs/Apr30_21-00-28_2da5c548e99e/events.out.tfevents.1651352518.2da5c548e99e.1050.7\n","MBart-finetuned-en-to-id/runs/Apr30_21-00-28_2da5c548e99e/1651352518.7937372/events.out.tfevents.1651352518.2da5c548e99e.1050.8\n"]}],"source":["import os\n","for dirname, _, filenames in os.walk('MBart-finetuned-en-to-id'):\n","   for filename in filenames:\n","       print(os.path.join(dirname, filename))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MT5jLzN3CpSv"},"outputs":[],"source":["from transformers import MBart50TokenizerFast, MBartForConditionalGeneration\n","src_text = [\"USA Today is an American daily middle-market newspaper that is the flagship publication of its owner, Gannett. Founded by Al Neuharth on September 15, 1982.\"]\n","model_name = 'MBart-finetuned-en-to-id'\n","tokenizer = MBart50TokenizerFast.from_pretrained(model_name,src_lang=\"en_XX\")\n","model = MBartForConditionalGeneration.from_pretrained(model_name)\n","model_inputs = tokenizer(src_text, return_tensors=\"pt\")\n","# translate from English to Hindi\n","generated_tokens = model.generate(\n","   **model_inputs,forced_bos_token_id=tokenizer.lang_code_to_id[\"de_DE\"])\n","translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n","translation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":155,"status":"ok","timestamp":1651348097451,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"vKycVa1JBCOg","outputId":"e86539bc-94d7-4394-ddbb-56a1348721dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: NEPTUNE_PROJECT=dannysilitonga/NLPII\n"]}],"source":["# %env NEPTUNE_PROJECT= dannysilitonga/NLPII\n","# %env NEPTUNE_API_TOKEN=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI1ODQ0NWE5NS1kNjc0LTRjZTgtOTE0YS02Y2RjOTY4Y2IwZjcifQ==\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":305,"status":"ok","timestamp":1651348381781,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"qVOzAz_pBOOo","outputId":"429d1e6c-a141-41a9-88c2-32c8c220eea4"},"outputs":[{"name":"stdout","output_type":"stream","text":["declare -x NEPTUNE_API_TOKEN=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI1ODQ0NWE5NS1kNjc0LTRjZTgtOTE0YS02Y2RjOTY4Y2IwZjcifQ==\"\n","declare -x NEPTUNE_PROJECT=\"dannysilitonga/NLPII\"\n"]}],"source":["import os\n","os.environ['NEPTUNE_PROJECT'] = \"dannysilitonga/NLPII\"\n","os.environ['NEPTUNE_API_TOKEN'] = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI1ODQ0NWE5NS1kNjc0LTRjZTgtOTE0YS02Y2RjOTY4Y2IwZjcifQ==\"\n","!export | grep NEPTUNE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WOP88NbzDWVs"},"outputs":[],"source":["import neptune"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2901,"status":"ok","timestamp":1651348714301,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"NArlZg1p-IGp","outputId":"04d33205-9e41-4bab-a0ac-08dd703d780b"},"outputs":[{"name":"stderr","output_type":"stream","text":["Info (NVML): Driver Not Loaded. GPU usage metrics may not be reported. For more information, see https://docs-legacy.neptune.ai/logging-and-managing-experiment-results/logging-experiment-data.html#hardware-consumption \n"]},{"name":"stdout","output_type":"stream","text":["https://app.neptune.ai/dannysilitonga/NLPII/e/NLPII-1\n"]},{"data":{"text/plain":["Experiment(NLPII-1)"]},"execution_count":110,"metadata":{},"output_type":"execute_result"}],"source":["# import neptune.new as neptune\n","run=neptune.init(project_qualified_name=\"dannysilitonga/NLPII\", \n","                 api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI1ODQ0NWE5NS1kNjc0LTRjZTgtOTE0YS02Y2RjOTY4Y2IwZjcifQ==\")\n","neptune.create_experiment()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"elapsed":163030,"status":"ok","timestamp":1651349063956,"user":{"displayName":"Danny Silitonga","userId":"11468896110584393200"},"user_tz":240},"id":"KOkz3uBP_0gR","outputId":"ed41cade-2855-4174-fadb-ead15ea1889c"},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 1000\n","  Batch size = 16\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [63/63 02:29]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["evaluate_results = trainer.evaluate()\n","neptune.log_metric('epoch',evaluate_results['epoch'])\n","neptune.log_metric('bleu',evaluate_results['eval_bleu'])\n","neptune.log_metric('meteor',evaluate_results['eval_meteor'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZL947Pc6EIsJ"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"fine_tune_model_id_en.ipynb","provenance":[],"authorship_tag":"ABX9TyOtPhlSZtkON4kB/h+ZZYvU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"016f7e86dff845a48de58489382ebe09":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"028c5e2ebc9e464fadbc7285a4e035e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0426e23aaee24584a6c951d775705a68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0afdd008cf5e40c0af788063e124931c","placeholder":"​","style":"IPY_MODEL_4a148438382547f8a449b12c8b8bbe2a","value":" 10.9k/? [00:00&lt;00:00, 478kB/s]"}},"04cf6c8ba1804120ac3e65d94c37355d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"059ecc4fbc6940f281596f9581739cd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"073f687aaec14c048de95a35d4c16299":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aab036bb3ef2401a89aadfc7f48ab9fa","placeholder":"​","style":"IPY_MODEL_fcee4a5e6f4a4bdfab3344600c40ebcf","value":"Downloading: 100%"}},"07975831e30249c183ea04b2e48c039c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07b81ca901144742b4b0c53ca1b9fc11":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08cabece265b47e483c86ede41ef09e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_979ffe4a2b9f4a5d8d4e89cd398d2bd8","max":528,"min":0,"orientation":"horizontal","style":"IPY_MODEL_985cc881f04c4a45b7891f36ffe7f8f3","value":528}},"09f5ebbe208146048a4874a4364afd84":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a3b684d47344ba0b51c7730d8942861":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a52b5832c394b3e974ffbd5f4424397":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0afdd008cf5e40c0af788063e124931c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e115c2051564282b3a55315e9cfe9e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5adcbf032a49476daf4466b21399e89d","IPY_MODEL_08cabece265b47e483c86ede41ef09e2","IPY_MODEL_93305e5242dd42afa8e4ac8babb770fb"],"layout":"IPY_MODEL_66e1513114c3434f96ee79b85148f016"}},"10badb8dba90407ebdab80d231fa2b95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83446a27061f4b788e2516d1a1f8c6e3","placeholder":"​","style":"IPY_MODEL_566758f2ab1f4423965e0dfec6241006","value":"Downloading: 100%"}},"13cbcdeeeb40466495ed48a5c2bc6b70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_60bed3deb77e46c3a9f77eb16e9e6e5b","IPY_MODEL_30080f9cfcf546acaf31a258637e3287","IPY_MODEL_3f8e7eb733084c6fb5826aa5c7b0a3f5"],"layout":"IPY_MODEL_e6c67e7ac95c4a6b9ec9a17a2c531ce0"}},"14c2d57f5e654eb1b5bfdf00982fe26e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15e1f85697fc45c18f5b63e60365e87f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15ff2195a9fe4a429546894578b219a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4058f40961db4b61958215fff9393d64","IPY_MODEL_225cc2fe6b2045309a035668bac02955","IPY_MODEL_16bf3e1c42f34c6c8e9d8f6201603777"],"layout":"IPY_MODEL_c557fa2721394465941ac49a88013956"}},"16bf3e1c42f34c6c8e9d8f6201603777":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d51f361c27c443aa9a3a0dff9305b02","placeholder":"​","style":"IPY_MODEL_73908abb07f54b00bdc865cb5991991f","value":" 782k/782k [00:00&lt;00:00, 639kB/s]"}},"1709b55f984e423fad8ef89427282ddc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"179c77df68ca45f393bd0c02d791ca86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a3b684d47344ba0b51c7730d8942861","placeholder":"​","style":"IPY_MODEL_a9091529567a4549b6a4ed0a787b7491","value":" 1.11k/1.11k [00:00&lt;00:00, 47.8kB/s]"}},"1c2a7985312f4aba8944cb6349010ebb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e389bce39b04129be27e5389f875d9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ebf4b30011448ba82a5fad89bd68dc4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ef91de2278b495391e58a0b9cbd32a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f30902ba5fcc49fa901c82f7ba341e1d","max":7415,"min":0,"orientation":"horizontal","style":"IPY_MODEL_41c3c823ccf047f2a23dbabdf862b6de","value":7415}},"1fa81d6b52424c59856c43714fc9026a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4afde4be70a84f2ba36380d9970c774a","placeholder":"​","style":"IPY_MODEL_d3922a70290e432098a88c63251ad032","value":" 261M/261M [00:05&lt;00:00, 52.6MB/s]"}},"1fac790318e342bfa20046ebc52e99ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_07b81ca901144742b4b0c53ca1b9fc11","max":2199,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a4e0da45aee422e97ba6ed2f4709b22","value":2199}},"20d52570cf744717bc23a4af4d7ad400":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"225cc2fe6b2045309a035668bac02955":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_07975831e30249c183ea04b2e48c039c","max":800687,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7417377e241648d9848cc5552ab758cd","value":800687}},"2266d28e8d0f48cb9c698f922043fa91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"233317d26f784026b77df7ccb5836837":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24dbd44d39d848abba46588288e8716b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"256966a30b8b4634a469aaa71b3d4240":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3623c6c7cfb84ebb8b26edf587e267e6","IPY_MODEL_1ef91de2278b495391e58a0b9cbd32a8","IPY_MODEL_7ceba01948ac447d9a6f2fad4cc905e0"],"layout":"IPY_MODEL_51091fb09afa45f0ac01e753499d6104"}},"25ca514345764040bd04a0a442b9635e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27aba90c01794d5a86e36bb57e888b94":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27e2ef51344a4557908d34409cc38371":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2806aa1f76244d2c896cb9aea9f05fc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b12d916a54744e69287244246704233","placeholder":"​","style":"IPY_MODEL_f92b9ae1c8fa49daaf773e5d08576422","value":" 35/35 [01:09&lt;00:00,  1.90s/ba]"}},"2c425e4123b247e08b807a31dc8ee390":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c6a243b447c47b288a0dde3ec5fb340":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c4a0b4b39dcf4386924fe1ac8a0deabd","IPY_MODEL_c3fdc10faa3044ea9125aa1c5af3eeee","IPY_MODEL_c175afb9479948f49f12f4608e7215c8"],"layout":"IPY_MODEL_cf3734747d92484f9f2908e88bbec7f0"}},"2d27691eec8448df9dac8a91d6f04997":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2dc9e7ff0a5346959a050d40643d59af":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f3f2477248f41c9b6aa868ca8c558fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30080f9cfcf546acaf31a258637e3287":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_836597a980a645e682ed7f1caf6eff72","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bb4d4b5bb286491193d9d9c5edc8cbdc","value":1}},"30b29f05deee41e287a7b711fc689711":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"321b9a8602aa4db99048836d074e843c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32e78dd6e2fb4f4cba6a755c9a9af601":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"339efe75bbc243d9ac88a2436064b652":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33a757b8e48541a3a7295f8e15893874":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"340066a5fbfa42d0bba9789f125c839a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_790a499797f14544839b19e94fb09d3b","max":2269,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e8cc05fb9c1a47459b9fe787ce06f317","value":2269}},"3623c6c7cfb84ebb8b26edf587e267e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b1589c2037443029a7662e230b2832f","placeholder":"​","style":"IPY_MODEL_5ccdf08ab63c46d29ce8ba4782bf1b79","value":"100%"}},"396b056c5f584f728b7899714e9d5a47":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39c31457f69f4161a6eba9bda741d332":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39eb70430aa3440eb2977bb2ea4ca913":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b68930dd502144209fa1388882f1def0","max":35,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f13073e7bba46b3a981fe54faaa6dc6","value":35}},"3a22b300e9064c558436ba043b459b39":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6571071bbd414b91917788f6f8e83b94","placeholder":"​","style":"IPY_MODEL_0a52b5832c394b3e974ffbd5f4424397","value":"Downloading: 100%"}},"3ac86cf829774ac8bb5a4281b0bb3c1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c6819511d1a47bda9de766661fbbb52":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ccbaf755eb14172a75445a4cd35b168":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d505402d3474d7e84aaa1bcc7b045c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d51f361c27c443aa9a3a0dff9305b02":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e358edef31f406595b539ba3938c44d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b471bf694174f7daa99c0542bed8e45","IPY_MODEL_d7a58349ebf34a3b9e215706a89d4d22","IPY_MODEL_fd8c92f161974e449ecd95d17cb8ab10"],"layout":"IPY_MODEL_3ccbaf755eb14172a75445a4cd35b168"}},"3f8e7eb733084c6fb5826aa5c7b0a3f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e5dde095f494205b5b1e47dabbe5118","placeholder":"​","style":"IPY_MODEL_523bb89292a04e9388b567d64d4d9a2c","value":" 9267478/0 [20:59&lt;00:00, 7965.62 examples/s]"}},"4058f40961db4b61958215fff9393d64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f20d5ad892cb4474aa42992feb9e07ad","placeholder":"​","style":"IPY_MODEL_7902cf984322470c967107857a93d42a","value":"Downloading: 100%"}},"41c3c823ccf047f2a23dbabdf862b6de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"41c54e6991d9497598df1aa728930051":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a58c8804ebc43b09398108ece0765cc","IPY_MODEL_5b2765959fdf42ecbf7ae14d3683c903","IPY_MODEL_45a6a0a9cad848cd904617fde51c3e5e"],"layout":"IPY_MODEL_b3ff0bd5955b41b8b1389e3eafea7742"}},"44fab7ef183c4dd4b85badbfc1d9bc16":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45a6a0a9cad848cd904617fde51c3e5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd3ec62eb0fa44368df188aa16ae4870","placeholder":"​","style":"IPY_MODEL_71b02b116c5a4d4b9627a816fa2448ac","value":" 1.20M/1.20M [00:00&lt;00:00, 1.93MB/s]"}},"47a51c232dff4131bc4c9d1c53c0f426":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8155324cc00c4118913e12bd8fd7b115","max":35,"min":0,"orientation":"horizontal","style":"IPY_MODEL_14c2d57f5e654eb1b5bfdf00982fe26e","value":35}},"4a148438382547f8a449b12c8b8bbe2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4afde4be70a84f2ba36380d9970c774a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b73e951939d4605ae5374c83f9c42eb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e2e456f5d354bc9a262b0d835f9a32d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f8176d235ca4f508b49a4f78e108f03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51091fb09afa45f0ac01e753499d6104":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"523bb89292a04e9388b567d64d4d9a2c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"525c58a2e1e843718b278a2a6f19aa44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5320ffb8ced5426c9762345e7171f07a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_87ecfeece49749ddac1d33319e0bc9ca","max":1133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_525c58a2e1e843718b278a2a6f19aa44","value":1133}},"535b957b74c041b38ebd7c923720c827":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5487176a237646799fee62f029d1914b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54dd01563bfc4aafa2ae90c9a2841fda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b73e951939d4605ae5374c83f9c42eb","placeholder":"​","style":"IPY_MODEL_321b9a8602aa4db99048836d074e843c","value":"Downloading: 100%"}},"566758f2ab1f4423965e0dfec6241006":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5689c3fa4f9a44a7aea9f40334cf1360":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"568e13b8470c4a88a17d4afc84943602":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5724a4831c0f48d49982b0b9757f885e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27aba90c01794d5a86e36bb57e888b94","placeholder":"​","style":"IPY_MODEL_94f6c20c3aff440ea17a7a5e3ad48ec0","value":"Downloading builder script: "}},"57e19b3c06e44b119cc3074a815d3d10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6e95651636c6476280e6b5803a4a2bd0","IPY_MODEL_ba9be01c0cab4993829ddc6b60a51602","IPY_MODEL_b36b66b32ae34406b1a8c67fed182045"],"layout":"IPY_MODEL_4f8176d235ca4f508b49a4f78e108f03"}},"58f1bab7be894f7c827542b0bf9b2406":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8772cc0bf30546a19f13c3bbea28983c","placeholder":"​","style":"IPY_MODEL_d619c94a8bcc407aa5fa1335cb7ee844","value":"Downloading metadata: "}},"5adcbf032a49476daf4466b21399e89d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7892b12329a4e469c70681715dfffad","placeholder":"​","style":"IPY_MODEL_2266d28e8d0f48cb9c698f922043fa91","value":"Downloading: 100%"}},"5b1589c2037443029a7662e230b2832f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b2765959fdf42ecbf7ae14d3683c903":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2dc9e7ff0a5346959a050d40643d59af","max":1257390,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b01c25a465ab48688683946ed375a331","value":1257390}},"5b6c3365cbc2406893255fc2b6a76a8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_339efe75bbc243d9ac88a2436064b652","placeholder":"​","style":"IPY_MODEL_75d2a7dafae0431f809a903863b99d5c","value":"Downloading builder script: "}},"5c38bb417d7845169a27ac1b45a8a838":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c493b8aa2d747b99c167557beee9d75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c753322cac042f1b8d917f666025521","IPY_MODEL_47a51c232dff4131bc4c9d1c53c0f426","IPY_MODEL_2806aa1f76244d2c896cb9aea9f05fc9"],"layout":"IPY_MODEL_e9478b14d3e5486f81acc4500d73896e"}},"5ccdf08ab63c46d29ce8ba4782bf1b79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5da84f48509a4fa78ce566aa096a5765":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5daa18b25ed54b3aad8fdda8adf789c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5724a4831c0f48d49982b0b9757f885e","IPY_MODEL_7a8f80c46a774e06b2e212767094fe68","IPY_MODEL_ef240b71b883479da040485ec84ceb1c"],"layout":"IPY_MODEL_5689c3fa4f9a44a7aea9f40334cf1360"}},"5fe003a4b127450b93be7688286e2757":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4ae5e20841e46c79e5d226d5c50c6df","max":260734701,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a27283c1ce084e8f85a9b3ba5843f0fa","value":260734701}},"5ff57338b1c949689156dc5c894eb008":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6031bedbcb86448eb48899825e60f1f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_073f687aaec14c048de95a35d4c16299","IPY_MODEL_fdcc1e5745c94b31892b382192a3921b","IPY_MODEL_a7a49c0d0b9148928cb8031f4fdd824b"],"layout":"IPY_MODEL_5487176a237646799fee62f029d1914b"}},"60bc7b76baf74712868269885965fbd8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60bed3deb77e46c3a9f77eb16e9e6e5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32e78dd6e2fb4f4cba6a755c9a9af601","placeholder":"​","style":"IPY_MODEL_c337e58e26164402ae8ee6b3f22fc8a1","value":"Generating train split: "}},"614def8989694fcca71ae35dc7697415":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62e1012e6be648728257418b08fa0d35":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64b7dcc3f40d4269987588cd56845b60":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6571071bbd414b91917788f6f8e83b94":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66e1513114c3434f96ee79b85148f016":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"683163103ffd40958b90872620e54caa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e95651636c6476280e6b5803a4a2bd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9ffed1821ed4213affbfb473ce0bc33","placeholder":"​","style":"IPY_MODEL_2d27691eec8448df9dac8a91d6f04997","value":"100%"}},"6ef5268580fd4e39b37d369fa396386c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6f223a1f1e9f4327bb94f2a928855e64":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"710da2f7aecd4291994dbd6570f11332":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44fab7ef183c4dd4b85badbfc1d9bc16","placeholder":"​","style":"IPY_MODEL_711eb042d04349fc93b32fc36f02cdcd","value":" 6.22k/? [00:00&lt;00:00, 246kB/s]"}},"711eb042d04349fc93b32fc36f02cdcd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71b02b116c5a4d4b9627a816fa2448ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72685051ee2041799514c788be759a13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73908abb07f54b00bdc865cb5991991f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7417377e241648d9848cc5552ab758cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"741ca23e67fa47d6aea5d477625b6c0c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3a22b300e9064c558436ba043b459b39","IPY_MODEL_93f47689f17144058e40d473c2ce8ac6","IPY_MODEL_fd0724ca2d6947e5bedbd0e4e6b25bf6"],"layout":"IPY_MODEL_c3d1534a71e445dbb91d67fa90822c7a"}},"7466ecb70e234922b1388bdda7015568":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62e1012e6be648728257418b08fa0d35","placeholder":"​","style":"IPY_MODEL_059ecc4fbc6940f281596f9581739cd6","value":" 717/717 [00:00&lt;00:00, 26.8kB/s]"}},"75837616283d4696b09aff0907faba44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75d2a7dafae0431f809a903863b99d5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"769da42e59fe4c97b8071f0d02c57ad8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76f380a251cb4775b9419e027ad8280e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"780a4e0580a746d29c1685b91865a1a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7902cf984322470c967107857a93d42a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"790a499797f14544839b19e94fb09d3b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a4e0da45aee422e97ba6ed2f4709b22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a8f80c46a774e06b2e212767094fe68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_016f7e86dff845a48de58489382ebe09","max":2199,"min":0,"orientation":"horizontal","style":"IPY_MODEL_780a4e0580a746d29c1685b91865a1a2","value":2199}},"7b551e4c30cc4c59926197b85291e98e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bab4c19693c4711bdc1dfdc6c251a8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef67951e580141a1a2f3e472cc025a42","max":42,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff7d05452a3d4f3f966ac113e7f516f2","value":42}},"7c0de156195d4c739adb8c7b36f9bb46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a844b23d46d4816a1aaba6473579c7d","placeholder":"​","style":"IPY_MODEL_3ac86cf829774ac8bb5a4281b0bb3c1e","value":" 4.83M/4.83M [00:00&lt;00:00, 35.8MB/s]"}},"7c4f1052b7454cd787034d019f654294":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ceba01948ac447d9a6f2fad4cc905e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72685051ee2041799514c788be759a13","placeholder":"​","style":"IPY_MODEL_7d38f289999f45c69208cb7d4f7fda09","value":" 7415/7415 [24:24&lt;00:00,  6.06ba/s]"}},"7d38f289999f45c69208cb7d4f7fda09":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7da6434900d3437494013cb7546b0d11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e24d8494b2b432d9e2085547bac86f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ecdc8c0248d420ba27f9f9c70999f16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c38bb417d7845169a27ac1b45a8a838","placeholder":"​","style":"IPY_MODEL_9eb2fa19d6e4483d9ac60238283a20dd","value":" 7.65k/? [00:00&lt;00:00, 291kB/s]"}},"7f33e04d51c4448d9197a5169c9bdf46":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8155324cc00c4118913e12bd8fd7b115":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83446a27061f4b788e2516d1a1f8c6e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"836597a980a645e682ed7f1caf6eff72":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"84f75fe1ad1c4607930789ae9cb37e75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abec2930db8d40e69574b8979a440c5d","placeholder":"​","style":"IPY_MODEL_4e2e456f5d354bc9a262b0d835f9a32d","value":"Downloading: 100%"}},"85807622faf34f8c9189dc04ff70bba1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d505402d3474d7e84aaa1bcc7b045c3","placeholder":"​","style":"IPY_MODEL_233317d26f784026b77df7ccb5836837","value":"Downloading data: 100%"}},"85d8f484366045fb8d4226255b40da33":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8772cc0bf30546a19f13c3bbea28983c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87ecfeece49749ddac1d33319e0bc9ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"889dfd625ca442d6a56d40c6ba938a06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec6f03b1efc14d42813648727da5568a","IPY_MODEL_340066a5fbfa42d0bba9789f125c839a","IPY_MODEL_710da2f7aecd4291994dbd6570f11332"],"layout":"IPY_MODEL_39c31457f69f4161a6eba9bda741d332"}},"8a58c8804ebc43b09398108ece0765cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8df51dca54d94ffcbe2249fdebdc4931","placeholder":"​","style":"IPY_MODEL_5ff57338b1c949689156dc5c894eb008","value":"Downloading: 100%"}},"8b21ebbfda3f465d936e66cbfed82564":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b2b543abd134dea91c8fe37a1b2360b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b3cf22fc7d6416ba8da746235b931de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8df51dca54d94ffcbe2249fdebdc4931":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e5dde095f494205b5b1e47dabbe5118":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fab9f18082c475ebf2a960fb60f9f8a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90be442142f44b1ea889b789f9111c9a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90dcc31e72d648bbbeae751b4e25e822":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93305e5242dd42afa8e4ac8babb770fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6517d2802994e12b6b60ff129a2bc44","placeholder":"​","style":"IPY_MODEL_5da84f48509a4fa78ce566aa096a5765","value":" 528/528 [00:00&lt;00:00, 17.6kB/s]"}},"93f47689f17144058e40d473c2ce8ac6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3a339662abc451ea3ba6a7f0824d65b","max":1428,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ef5268580fd4e39b37d369fa396386c","value":1428}},"94f6c20c3aff440ea17a7a5e3ad48ec0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"979b5d121bfd40b8a5a88cd82045d6db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_683163103ffd40958b90872620e54caa","max":795925,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a86f5925ca3d4aacb3a51388068e46d2","value":795925}},"979ffe4a2b9f4a5d8d4e89cd398d2bd8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9804f6f02ba34a30a23dd12c35d3bfd5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"985cc881f04c4a45b7891f36ffe7f8f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98c0eab6a5704263bb11f6d6160b7e06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_028c5e2ebc9e464fadbc7285a4e035e0","placeholder":"​","style":"IPY_MODEL_e8449742b21e4684bf5d811f12b7e2e3","value":"Downloading: 100%"}},"9a844b23d46d4816a1aaba6473579c7d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b12d916a54744e69287244246704233":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b471bf694174f7daa99c0542bed8e45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90be442142f44b1ea889b789f9111c9a","placeholder":"​","style":"IPY_MODEL_1c2a7985312f4aba8944cb6349010ebb","value":"100%"}},"9c753322cac042f1b8d917f666025521":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_396b056c5f584f728b7899714e9d5a47","placeholder":"​","style":"IPY_MODEL_9804f6f02ba34a30a23dd12c35d3bfd5","value":"Creating CSV from Arrow format: 100%"}},"9eb2fa19d6e4483d9ac60238283a20dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f13073e7bba46b3a981fe54faaa6dc6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9fc728c8b9654a43871884c7ae012fac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64b7dcc3f40d4269987588cd56845b60","placeholder":"​","style":"IPY_MODEL_7da6434900d3437494013cb7546b0d11","value":"Creating CSV from Arrow format: 100%"}},"a047892cbd5d42339837a1ff6769bb2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a07c4dd66760488ca08ba9e8ea445d62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a27283c1ce084e8f85a9b3ba5843f0fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a45658cd1aa6436a83801a762247dcd8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_98c0eab6a5704263bb11f6d6160b7e06","IPY_MODEL_979b5d121bfd40b8a5a88cd82045d6db","IPY_MODEL_b8b0c36cb6b24cde84453dd3acf1b53c"],"layout":"IPY_MODEL_7b551e4c30cc4c59926197b85291e98e"}},"a7892b12329a4e469c70681715dfffad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7a49c0d0b9148928cb8031f4fdd824b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9051819d73f438ca32917292f5327aa","placeholder":"​","style":"IPY_MODEL_30b29f05deee41e287a7b711fc689711","value":" 278M/278M [00:04&lt;00:00, 65.9MB/s]"}},"a86f5925ca3d4aacb3a51388068e46d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a8e7af530c784b838d3f8d6f956ead4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a9091529567a4549b6a4ed0a787b7491":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aab036bb3ef2401a89aadfc7f48ab9fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abec2930db8d40e69574b8979a440c5d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abefca5253e941c69c214e040db6c2e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f223a1f1e9f4327bb94f2a928855e64","max":1534,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e389bce39b04129be27e5389f875d9c","value":1534}},"ac88d07ddb6540c48484a12767b3342f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b01c25a465ab48688683946ed375a331":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b36b66b32ae34406b1a8c67fed182045":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5a169d447ff49df9590aaa1559205b4","placeholder":"​","style":"IPY_MODEL_8b3cf22fc7d6416ba8da746235b931de","value":" 1/1 [00:00&lt;00:00, 22.76it/s]"}},"b3ff0bd5955b41b8b1389e3eafea7742":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b68930dd502144209fa1388882f1def0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8b0c36cb6b24cde84453dd3acf1b53c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ebf4b30011448ba82a5fad89bd68dc4","placeholder":"​","style":"IPY_MODEL_d73a63dd5a41422ba22d14b9d1411081","value":" 777k/777k [00:00&lt;00:00, 1.35MB/s]"}},"ba9be01c0cab4993829ddc6b60a51602":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f724d66f96494647b347efd8d9d793e5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_da3f69c007f044d5a5542ef5099e5146","value":1}},"bb4d4b5bb286491193d9d9c5edc8cbdc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bec144cd6b174bcb847484997e27f65d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_85d8f484366045fb8d4226255b40da33","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_75837616283d4696b09aff0907faba44","value":5069051}},"c175afb9479948f49f12f4608e7215c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f98080bce3284d3c85330aec979c7950","placeholder":"​","style":"IPY_MODEL_568e13b8470c4a88a17d4afc84943602","value":" 7.65k/? [00:00&lt;00:00, 209kB/s]"}},"c337e58e26164402ae8ee6b3f22fc8a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c3d1534a71e445dbb91d67fa90822c7a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3fdc10faa3044ea9125aa1c5af3eeee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b2b543abd134dea91c8fe37a1b2360b","max":2848,"min":0,"orientation":"horizontal","style":"IPY_MODEL_769da42e59fe4c97b8071f0d02c57ad8","value":2848}},"c4a0b4b39dcf4386924fe1ac8a0deabd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed8540c894d748988182d977ee7d3473","placeholder":"​","style":"IPY_MODEL_ac88d07ddb6540c48484a12767b3342f","value":"Downloading builder script: "}},"c557fa2721394465941ac49a88013956":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c733364ded9142c1b5893a3c2a03da58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dcb7fa7499c94fa2b0e2b033c7852db1","IPY_MODEL_1fac790318e342bfa20046ebc52e99ea","IPY_MODEL_e72fc4dda04d4dfeabc6360bf884b372"],"layout":"IPY_MODEL_dd87f8ad032340e1aa8efeed1b7e36eb"}},"c9ffed1821ed4213affbfb473ce0bc33":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb441a0a9247425c944d58fd9831ce9e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf3734747d92484f9f2908e88bbec7f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d097a6b5fa684abcab4903cd693f430b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3428049976e435e87f5ada9dbe902fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3922a70290e432098a88c63251ad032":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d45597bfaa5d46cf8e5d5829242c41b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15e1f85697fc45c18f5b63e60365e87f","placeholder":"​","style":"IPY_MODEL_04cf6c8ba1804120ac3e65d94c37355d","value":" 42.0/42.0 [00:00&lt;00:00, 1.74kB/s]"}},"d4ae5e20841e46c79e5d226d5c50c6df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4bb429fd2d049aeafc5b169016a8526":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85807622faf34f8c9189dc04ff70bba1","IPY_MODEL_5fe003a4b127450b93be7688286e2757","IPY_MODEL_1fa81d6b52424c59856c43714fc9026a"],"layout":"IPY_MODEL_535b957b74c041b38ebd7c923720c827"}},"d619c94a8bcc407aa5fa1335cb7ee844":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d73a63dd5a41422ba22d14b9d1411081":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7a58349ebf34a3b9e215706a89d4d22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c6819511d1a47bda9de766661fbbb52","max":1854,"min":0,"orientation":"horizontal","style":"IPY_MODEL_20d52570cf744717bc23a4af4d7ad400","value":1854}},"d87144d2edff4c59a4455198d5402f1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b6c3365cbc2406893255fc2b6a76a8c","IPY_MODEL_dba30f2902184678a6bb614a2c4fb4fc","IPY_MODEL_7ecdc8c0248d420ba27f9f9c70999f16"],"layout":"IPY_MODEL_1709b55f984e423fad8ef89427282ddc"}},"da3f69c007f044d5a5542ef5099e5146":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dba30f2902184678a6bb614a2c4fb4fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb441a0a9247425c944d58fd9831ce9e","max":2848,"min":0,"orientation":"horizontal","style":"IPY_MODEL_24dbd44d39d848abba46588288e8716b","value":2848}},"dcb7fa7499c94fa2b0e2b033c7852db1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60bc7b76baf74712868269885965fbd8","placeholder":"​","style":"IPY_MODEL_25ca514345764040bd04a0a442b9635e","value":"Downloading builder script: "}},"dd87f8ad032340e1aa8efeed1b7e36eb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df38dde199364792a9cfbeb77293f32c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_33a757b8e48541a3a7295f8e15893874","max":717,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e018b7306dbb451aa3af333be8196904","value":717}},"e018b7306dbb451aa3af333be8196904":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e11a904b9cc24543beb6830f2dc25d86":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6843ff996724b85b3a2e8b6ac027490":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e11a904b9cc24543beb6830f2dc25d86","placeholder":"​","style":"IPY_MODEL_d3428049976e435e87f5ada9dbe902fc","value":"Downloading: 100%"}},"e6c67e7ac95c4a6b9ec9a17a2c531ce0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e72fc4dda04d4dfeabc6360bf884b372":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c4f1052b7454cd787034d019f654294","placeholder":"​","style":"IPY_MODEL_7e24d8494b2b432d9e2085547bac86f2","value":" 5.34k/? [00:00&lt;00:00, 206kB/s]"}},"e765d932455a46e8b210328a9a9f22ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8449742b21e4684bf5d811f12b7e2e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e89c7cc6bcb44202944421cf6bb71a3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7f275e6f6c54b52a0b177aa555de2b7","placeholder":"​","style":"IPY_MODEL_a047892cbd5d42339837a1ff6769bb2f","value":" 35/35 [01:11&lt;00:00,  2.00s/ba]"}},"e8cc05fb9c1a47459b9fe787ce06f317":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e9478b14d3e5486f81acc4500d73896e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec6f03b1efc14d42813648727da5568a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f24c7aa7633447ac8e8ec2e9e11b8186","placeholder":"​","style":"IPY_MODEL_614def8989694fcca71ae35dc7697415","value":"Downloading builder script: "}},"ed8540c894d748988182d977ee7d3473":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef240b71b883479da040485ec84ceb1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4fcc2f7d27047d1aba1521624bd5b8d","placeholder":"​","style":"IPY_MODEL_a8e7af530c784b838d3f8d6f956ead4c","value":" 5.34k/? [00:00&lt;00:00, 233kB/s]"}},"ef67951e580141a1a2f3e472cc025a42":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef7754f068644d209ed36c38bd7a9f6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54dd01563bfc4aafa2ae90c9a2841fda","IPY_MODEL_df38dde199364792a9cfbeb77293f32c","IPY_MODEL_7466ecb70e234922b1388bdda7015568"],"layout":"IPY_MODEL_76f380a251cb4775b9419e027ad8280e"}},"f20d5ad892cb4474aa42992feb9e07ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f24c7aa7633447ac8e8ec2e9e11b8186":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f30902ba5fcc49fa901c82f7ba341e1d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3a339662abc451ea3ba6a7f0824d65b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4b6d1c7f9b34d1f93ba7619202dc987":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e6843ff996724b85b3a2e8b6ac027490","IPY_MODEL_7bab4c19693c4711bdc1dfdc6c251a8d","IPY_MODEL_d45597bfaa5d46cf8e5d5829242c41b7"],"layout":"IPY_MODEL_09f5ebbe208146048a4874a4364afd84"}},"f4fcc2f7d27047d1aba1521624bd5b8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5a169d447ff49df9590aaa1559205b4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6517d2802994e12b6b60ff129a2bc44":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f724d66f96494647b347efd8d9d793e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7f275e6f6c54b52a0b177aa555de2b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9051819d73f438ca32917292f5327aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f92b9ae1c8fa49daaf773e5d08576422":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f98080bce3284d3c85330aec979c7950":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9f14d98398b4d8ea6338467ee140f63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_58f1bab7be894f7c827542b0bf9b2406","IPY_MODEL_abefca5253e941c69c214e040db6c2e0","IPY_MODEL_0426e23aaee24584a6c951d775705a68"],"layout":"IPY_MODEL_90dcc31e72d648bbbeae751b4e25e822"}},"fa1ea1137abd40d0a298a6e3e3357c1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_84f75fe1ad1c4607930789ae9cb37e75","IPY_MODEL_bec144cd6b174bcb847484997e27f65d","IPY_MODEL_7c0de156195d4c739adb8c7b36f9bb46"],"layout":"IPY_MODEL_d097a6b5fa684abcab4903cd693f430b"}},"fc5988eb139d49d59937db95e4238dd7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_10badb8dba90407ebdab80d231fa2b95","IPY_MODEL_5320ffb8ced5426c9762345e7171f07a","IPY_MODEL_179c77df68ca45f393bd0c02d791ca86"],"layout":"IPY_MODEL_8b21ebbfda3f465d936e66cbfed82564"}},"fcee4a5e6f4a4bdfab3344600c40ebcf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd0724ca2d6947e5bedbd0e4e6b25bf6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f3f2477248f41c9b6aa868ca8c558fe","placeholder":"​","style":"IPY_MODEL_a07c4dd66760488ca08ba9e8ea445d62","value":" 1.39k/1.39k [00:00&lt;00:00, 50.6kB/s]"}},"fd3ec62eb0fa44368df188aa16ae4870":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd6b05ecd12f402fa0aca80f48c96a4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9fc728c8b9654a43871884c7ae012fac","IPY_MODEL_39eb70430aa3440eb2977bb2ea4ca913","IPY_MODEL_e89c7cc6bcb44202944421cf6bb71a3a"],"layout":"IPY_MODEL_e765d932455a46e8b210328a9a9f22ae"}},"fd8c92f161974e449ecd95d17cb8ab10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fab9f18082c475ebf2a960fb60f9f8a","placeholder":"​","style":"IPY_MODEL_2c425e4123b247e08b807a31dc8ee390","value":" 1854/1854 [06:10&lt;00:00,  5.90ba/s]"}},"fdcc1e5745c94b31892b382192a3921b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f33e04d51c4448d9197a5169c9bdf46","max":291146349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27e2ef51344a4557908d34409cc38371","value":291146349}},"ff7d05452a3d4f3f966ac113e7f516f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}